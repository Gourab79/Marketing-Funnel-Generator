[
  {
    "text": "d selfpromotion thread post personal projects startups product placements collaboration needs blogs etc mention payment pricing requirements products services post link shorteners link aggregator websites autosubscribe links abuse trust lead bans encourage create new posts questions post instead thread stay alive posting date title meta experiment community nt like cancel encourage community promote work spamming main threads",
    "sentiment": "negative",
    "key_phrases": [
      "trust lead bans",
      "post instead",
      "spamming main"
    ]
  },
  {
    "text": "creation proof free creator learned hard way real responsibility proving big corporation endless resources global copyright registration s simple solution use free global copyright verification serviceistam instantly verify images pdfs audio video files app web website heres works free registrations log free points start need send direct message dm ill gladly provide free points need quick notes homegrown built uidesign basic effective permanent record registered content saved permanently nt changed mindful use use responsibly help manage server costs check website instructions app web",
    "sentiment": "neutral",
    "key_phrases": [
      "free global copyright",
      "real responsibility proving",
      "permanent record registered"
    ]
  },
  {
    "text": "d monthly s hiring wants hired job postings use template hiring location salary remote relocation time contract time brief overview looking looking jobs use template want hired location salary expectation remote relocation time contract time resume link resume brief overview looking remember community geared experience",
    "sentiment": "neutral",
    "key_phrases": [
      "job postings",
      "hiring location",
      "resume link"
    ]
  },
  {
    "text": "want hired remote salary remote contract time resume looking genai ai agents rag nlp data extraction chatbot ai automation related work",
    "sentiment": "neutral",
    "key_phrases": [
      "ai agents",
      "nlp data",
      "remote contract"
    ]
  },
  {
    "text": "want hired remote salary expectation month remote internshippart time resume interested mathematics dl implementation love work projects implement papers work new models",
    "sentiment": "positive",
    "key_phrases": [
      "remote internship",
      "dl implementation",
      "new models"
    ]
  },
  {
    "text": "want hired location egypt salary expectation minimum usd hour open remote relocation open time contract time freelancing resume published project multidimensional neural networks alternative transformers attention mechanism",
    "sentiment": "neutral",
    "key_phrases": [
      "neural networks",
      "salary expectation",
      "remote relocation"
    ]
  },
  {
    "text": "d aiml interviews like swe interviews people noticed aimlds job interviews feel swelike example relying data structures algorithms leetcode questions ve noticed professional friend groups people asked questions coding interview",
    "sentiment": "neutral",
    "key_phrases": [
      "aiml interviews",
      "data structures",
      "leetcode questions"
    ]
  },
  {
    "text": "ai engineer job swe ai trending nowadays integrating llms existing system",
    "sentiment": "neutral",
    "key_phrases": [
      "ai engineer",
      "llms existing",
      "job swe"
    ]
  },
  {
    "text": "ai research positions interviewed leetcode probably applying ai engineer nowadays swe ai surprising test coding",
    "sentiment": "neutral",
    "key_phrases": [
      "ai research",
      "leetcode probably",
      "ai engineer"
    ]
  },
  {
    "text": "ml big swe component leetcode type questions easy loweffort way pass filtering round start actual mlds interview",
    "sentiment": "positive",
    "key_phrases": [
      "ml big swe",
      "leetcode type",
      "easy loweffort"
    ]
  },
  {
    "text": "overwhelming majority people hiring positions idea screen candidates status quo data science started discipline",
    "sentiment": "negative",
    "key_phrases": [
      "status quo",
      "hiring positions",
      "data science"
    ]
  },
  {
    "text": "yes hate desire swe mle like research publishing frustrating focus leetcode swe principles rs positions available gatekept phds leetcode style questions joke",
    "sentiment": "negative",
    "key_phrases": [
      "research publishing",
      "leetcode style",
      "gatekept phds"
    ]
  },
  {
    "text": "personal experience big hard ml industry infrastructure tooling platforms train serve monitor models usually large companies people involved purely modelling lot people involved building infrastructure modelling place eventually production reliably",
    "sentiment": "neutral",
    "key_phrases": [
      "ml industry",
      "large companies",
      "building infrastructure"
    ]
  },
  {
    "text": "ve leetcode lot design discussions ml case study type discussions interviews certain point mle requires lot large scale design ml concepts",
    "sentiment": "neutral",
    "key_phrases": [
      "large scale",
      "ml concepts",
      "case study"
    ]
  },
  {
    "text": "field changed years ago daily routine defining metrics collecting data check quality finetuning bert resnet perform sort nlp cv tasks check wandb dashboard dealing training issue iterate deploy models ml engineer applied researcher decentralized onemodelfitall scenario prompt solve nlp cv problem era centralization need labs data curation model training eval deployment serve millions developers low supply makes bar extremely high research field changing lot maths older papers pre llm technical report prompt engineer paper",
    "sentiment": "neutral",
    "key_phrases": [
      "nlp cv tasks",
      "model training",
      "data curation"
    ]
  },
  {
    "text": "creative research ideas places ai software think distributed system use code run faster nt innovate actual distributed system protocol remaining places leading industrial reserach labs good research going general shift applied stuff closed models",
    "sentiment": "positive",
    "key_phrases": [
      "distributed system",
      "industrial reserach",
      "applied stuff"
    ]
  },
  {
    "text": "meta fair rs ask leetcode openai research scientists hard se medium ish problems expected know average lc company meta fair deepmind salesforce research amazon research tiktok openai anthropic etc rs ask leetcode bar high",
    "sentiment": "negative",
    "key_phrases": [
      "hard problems",
      "high bar",
      "leetcode ask"
    ]
  },
  {
    "text": "research labs larger research projects taking compute resources engineering projects scaling training large models",
    "sentiment": "neutral",
    "key_phrases": [
      "large models",
      "compute resources",
      "research projects"
    ]
  },
  {
    "text": "hi automated reasoning positions aws leetcode phase super simple questions easy level focused interview deep theoretical questions need phd level topic",
    "sentiment": "negative",
    "key_phrases": [
      "super simple",
      "deep theoretical",
      "phd level"
    ]
  },
  {
    "text": "d phase review discussion twophase reviewing main track phase reviews supplemented aigenerated nondecisional review phase additional reviews papers rejected phase author response phase papers rejected phase phase reviewed ai decide ur paper accepted phase rejected correct ai check formatting minor factors edit said use ai pilot program thoughtfully integrate llm technology specific points established review process supplementary firststage reviews llmgenerated reviews included component initial review stage providing additional perspective alongside traditional human expert evaluations discussion summary assistance llms assist senior program committee spc members summarizing reviewer discussions helping highlight key points consensus disagreement human reviewers",
    "sentiment": "positive",
    "key_phrases": [
      "ai pilot program",
      "llm technology",
      "review process"
    ]
  },
  {
    "text": "pilot program provide supplementary information form aigenerated reviews summaries contain ratings recommendations aigenerated supplementary reviews play formal role review process visible assigned reviewers submit reviews area chairs appropriate members program committee paper discussion phase addition aigenerated summaries reviewer discussions assist senior program committee members decision making",
    "sentiment": "neutral",
    "key_phrases": [
      "pilot program",
      "aigenerated reviews",
      "review process"
    ]
  },
  {
    "text": "thank sm clarification sense usual cases meta reviewers nt rebuttals authors properly depend initial ones umm understandable coz higher submissions low quality reviews metareviewers tired authors reviewers expect check llm generated reviews reviewers use ai review double ai crying author unlucky",
    "sentiment": "negative",
    "key_phrases": [
      "low quality",
      "tired reviewers",
      "ai generated"
    ]
  },
  {
    "text": "created marketing team cuttingedge methods rigorous safeguards exactly cuttingedge methods specific safeguards place zero transparency graduate students expected exhaust trying publish papers minor mistakes end careers",
    "sentiment": "negative",
    "key_phrases": [
      "cuttingedge methods",
      "zero transparency",
      "minor mistakes"
    ]
  },
  {
    "text": "d paper code completely paper code spammed compoletely coupld times like time lasted days",
    "sentiment": "negative",
    "key_phrases": [
      "paper code",
      "completely spammed",
      "coupld times"
    ]
  },
  {
    "text": "d nlp theory papers helpful industry research scientist roles currently m interested nlp theory questions count rs roles industry roles ai labs number papers help impression having papers purely theoretical help ai labs count number relevant papers exclude relevant theory paper yields strong empirical results important frame empirical paper maybe theory appendix compensate perceived weakness theoretical work topics languagevision models particularly relevant industry efficiency llms priority moe sparse attention structured sparsity approaches efficient llms",
    "sentiment": "neutral",
    "key_phrases": [
      "nlp theory papers",
      "industry research scientist",
      "empirical results"
    ]
  },
  {
    "text": "number papers screening metric nt matter reach interview stage said relevant papers relevant experience internships opensource work etc important having strong theory empirical results opinion better strong empirical results nt way hide theory discuss papers interview research talk frame work think best aligned team interviewing relevant topics entire pipeline data collectioncuration agentic model deploymentinference totally varies team team team care lot efficiency interested exploring reasoningrl techniques want best position roles d advise focus particular niche distinguish average applicant mind field moving fast hot topics today longer hot months interested think probably work better chasing trends drowning competition",
    "sentiment": "neutral",
    "key_phrases": [
      "strong theory",
      "empirical results",
      "research talk"
    ]
  },
  {
    "text": "disclaimer nt personally hiring anecdotal experience going process hearing friends colleagues nt want discourage way shot happens overall hard papers factor considered come unigroup wellknown advisor ll easily land interviews noname lab likewise having prior internship experience groups gdm meta nvidia etc extremely importanthelpful state market crucial currently senior researchers high demand phd grads dime dozen need bit luck patience rough guideline firstauthor conference papers minimum requirement competitive roles nowadays s great realistically talk bestmost relevant papers interview process probably nt apply job portals consider nonrs roles like mlere find ways signal value like internships opensource lastly usually skip screening",
    "sentiment": "neutral",
    "key_phrases": [
      "prior internship",
      "high demand",
      "conference papers"
    ]
  },
  {
    "text": "thanks s helpful need conferences good journals eg tmrl jmlr tacl count mixture good conferencejournal publications",
    "sentiment": "positive",
    "key_phrases": [
      "thanks helpful",
      "good journals",
      "good conference"
    ]
  },
  {
    "text": "d machine learning cheat sheet material linear algebra cheat sheet super vip cheatsheet artificial intelligence vip cheatsheet transformers large language models llms vip cheatsheet deep learning super vip cheatsheet machine learning ml machine learning cheat sheet ml cheatsheet documentation machine learning uc berkeley intro ml course notes machine learning probabilistic perspective",
    "sentiment": "neutral",
    "key_phrases": [
      "machine learning",
      "linear algebra",
      "deep learning"
    ]
  },
  {
    "text": "p looking thesis ideas extracting pipelines hi m currently starting masters thesis ill working topic automatically extracting pipelines scientific research papers core idea extract researchers actually process model evaluate data turning methods section structured stepwise listworkflow advisor project llms grobid semantic retrieval m looking ways extend approach problem differently ideally way s researchworthy practically useful initial idea ve brainstormed include extracting pipeline steps reconstructing directed graphs flat lists worked similar seen cool paperstools deal pipeline reconstruction reproducibility scientific method understanding love hear ideas think worth exploring common pain points method reporting addressed thanks advance",
    "sentiment": "positive",
    "key_phrases": [
      "extracting pipelines",
      "research papers",
      "structured workflow"
    ]
  },
  {
    "text": "d looking advice ml engineer ai architect facing challenges m working project conversational ai space hit roadblocks related system handles context tone scalability d appreciate quick chat experience building architecting intelligent assistants similar ml systems open brief conversation point right direction d super grateful happy share details dms",
    "sentiment": "positive",
    "key_phrases": [
      "conversational ai",
      "ml engineer",
      "intelligent assistants"
    ]
  },
  {
    "text": "start building current solution iterating itshowing perceived bottleneck organisation related work apparent draw",
    "sentiment": "neutral",
    "key_phrases": [
      "current solution",
      "perceived bottleneck",
      "organisation related"
    ]
  },
  {
    "text": "d llm companies deal cloudflares anticrawler protections turned default optout yesterday cloudflare announced protections ai crawler bots turned default website owners choose opt wish charging ai companies scraping websites pay crawl era ai companies simply recursively crawled websites simple requests extract data previously ai companies simply disrespected s anymore cloudflares protections crawler bots pretty sophisticated use generative ai produce scientifically correct unrelated content website order waste time compute crawlers ai labyrinth content pages humans supposed reach ai crawler bots reach invisible links special css techniques sophisticated display instance nonsense pages contain links nonsense pages crawler bots wasting time reading completely",
    "sentiment": "negative",
    "key_phrases": [
      "ai crawler bots",
      "cloudflare announced",
      "ai companies simply"
    ]
  },
  {
    "text": "scrapers win end daythe content accessible people cloudflare inherently disadvantaged arms race honestly nt expect cake eat want people able easily access content easily accessible easily accessible people easily scrapable try build protections safeguards end day motivated actor figure exploit inherent weakness defense",
    "sentiment": "negative",
    "key_phrases": [
      "arms race",
      "easily accessible",
      "inherent weakness"
    ]
  },
  {
    "text": "thought cloudflare trying raise capital llm companies pay cloudflare subscription fee shares buying company",
    "sentiment": "neutral",
    "key_phrases": [
      "cloudflare subscription",
      "raise capital",
      "llm companies"
    ]
  },
  {
    "text": "place google huge advantage going prohibit google crawling site kind google search index",
    "sentiment": "negative",
    "key_phrases": [
      "huge advantage",
      "google crawling",
      "search index"
    ]
  },
  {
    "text": "reminded nt good bear proof trash containers considerable overlap smartest bears stupid people game futile people tell difference valid content honey pot ai crawler surely able",
    "sentiment": "negative",
    "key_phrases": [
      "bear proof",
      "stupid people",
      "honey pot"
    ]
  },
  {
    "text": "nt imagine happening years ago google started click supposed imagine working literally imagine cloudflare suing openai winning like nyt wtvr new source legitimate case copyright happened",
    "sentiment": "negative",
    "key_phrases": [
      "google started",
      "suing openai",
      "legitimate case"
    ]
  },
  {
    "text": "behavioural cloning mouse movement human check selenium screengrab ocr cheaper llm post process scrape",
    "sentiment": "neutral",
    "key_phrases": [
      "behavioural cloning",
      "mouse movement",
      "selenium screengrab"
    ]
  },
  {
    "text": "works static pages modern crawlers like firecrawl actually render pages dynamic content like normal user cloudflare nt shit",
    "sentiment": "negative",
    "key_phrases": [
      "static pages",
      "cloudflare nt",
      "dynamic content"
    ]
  },
  {
    "text": "guess people improve sample efficiency ve experiments ideas direction m sure people trying years primary research interest nt think maybe adhoc stuff stuff came week worked badly presumably bunch ideas work great big problem llms actually obscure hallucination land best models overcoming nt simply data needs maybe having model prepare tomorrow requests x study repositories model developers script automatically generates things model practice relating things repository prepared knows detail",
    "sentiment": "negative",
    "key_phrases": [
      "primary research",
      "adhoc stuff",
      "overcoming hallucination"
    ]
  },
  {
    "text": "queue browser extensions scrape pages people actually looking guise removing ads",
    "sentiment": "negative",
    "key_phrases": [
      "browser extensions",
      "removing ads",
      "scrape pages"
    ]
  },
  {
    "text": "industry moved past pretraining internet data nt single byte web crawls nt change trajectory bit",
    "sentiment": "negative",
    "key_phrases": [
      "industry moved",
      "past pretraining",
      "change trajectory"
    ]
  },
  {
    "text": "said labyrinth throw http code web handle sort thing concrete reason microtransaction driven concept early took",
    "sentiment": "neutral",
    "key_phrases": [
      "http code",
      "concrete reason",
      "microtransaction driven"
    ]
  },
  {
    "text": "method potentially dangerous website owners scraper stuck looking useless pages stuck infinite loop especially unsophisticated scraper end costing hackers adapt point sleazy worth financially public companies nt exactly classic cybersecurity catandmouse hand hard time believing pay scrape catch likely succeeds scraping",
    "sentiment": "negative",
    "key_phrases": [
      "infinite loop",
      "sleazy website",
      "cybersecurity cat"
    ]
  },
  {
    "text": "disagree tried comprehensive content scrape microsoft google meta public content nt want scraped easy scrape small scale impossible scale similarly cloudflare turns tables arms race scale scale legal technology advantages smaller antiscrapers big player openai microsoft meta google shut legal threats effective restrict scrape massive scale detected quickly cloudflare scale tech advantage scrappy small scrapers nt care legal threats volume patterns figgerprints easier detect analyzing millions sites lets aware perfect solution fallacy case scrapers past time work",
    "sentiment": "negative",
    "key_phrases": [
      "arms race scale",
      "legal threats",
      "cloudflare scale"
    ]
  },
  {
    "text": "end daythe content accessible people ai labyrinth link describes cloudflare deploy decoy material detect unauthorized scraping nt crude including hidden links page discuss easily ignored said bots",
    "sentiment": "negative",
    "key_phrases": [
      "unauthorized scraping",
      "cloudflare deploy",
      "hidden links"
    ]
  },
  {
    "text": "users nt need served content nearly rate scrapers limit bot access level normal user effectively kills large scale scraping makes long inefficient way data acquisition discouraging emphasis effective long certainly load servers bit",
    "sentiment": "negative",
    "key_phrases": [
      "large scale scraping",
      "bot access level",
      "inefficient way"
    ]
  },
  {
    "text": "yeah bear human open trash bear eat trash human probably pinch nose walk away filling hidden links ai generated slop trap crawlers poison models training content return wo nt hurt users hurt models think main distinction nt trap create poisoning risk",
    "sentiment": "negative",
    "key_phrases": [
      "poison models",
      "ai generated",
      "hurt users"
    ]
  },
  {
    "text": "love metaphor thank sharing case like human imperceptible faint odor fish corner",
    "sentiment": "neutral",
    "key_phrases": [
      "human imperceptible",
      "faint odor",
      "case like"
    ]
  },
  {
    "text": "scraping unfavorable outcome llm companies end users find hard believe accept data scraped need new data",
    "sentiment": "negative",
    "key_phrases": [
      "unfavorable outcome",
      "end users",
      "data scraped"
    ]
  },
  {
    "text": "yeah fair point resources difficult expensive impression non expert legal things tends favour scraping publicly accessible information d threshold avoiding perfect solution fallacy personally feasibly maybe m experienced area average idk ve seen appear google scrapable mean reality places want scraped google look seo paid ads",
    "sentiment": "neutral",
    "key_phrases": [
      "resources difficult",
      "publicly accessible",
      "fallacy personally"
    ]
  },
  {
    "text": "nt likely openai instance team supposed find ways prevent crawlers detected blocked agree smaller companies struggle immensely large ai companies resources find workarounds",
    "sentiment": "negative",
    "key_phrases": [
      "openai instance",
      "prevent crawlers",
      "large ai companies"
    ]
  },
  {
    "text": "disagree tried comprehensive content scrape microsoft google meta public content nt want scraped easy scrape small scale impossible scale set daemons run couple residential ips scrape configure rotate ips modems blocked interval childs play company resources oai anthropic hundreds employees connections",
    "sentiment": "negative",
    "key_phrases": [
      "comprehensive content",
      "impossible scale",
      "rotate ips"
    ]
  },
  {
    "text": "yes challenge end day determine looking atrunning etc determine bot spoofing win try things ll win",
    "sentiment": "positive",
    "key_phrases": [
      "determine bot",
      "try things",
      "win try"
    ]
  },
  {
    "text": "bro meta bragged millions pirated books train llama nt consequences big players afraid legat threats todays world simply big",
    "sentiment": "negative",
    "key_phrases": [
      "pirated books",
      "big players",
      "legat threats"
    ]
  },
  {
    "text": "fast break things scale horizontally absolutely market share gemini app related launches jr dev levels absurd times period time month ago chat history entries actually deleted engaged chat way know happened exporting research document nt attempt interact gemini like chatgpt assume happening chats claude chatgpt let happen viewed catastrophic failure breech user trust gemini nt established high bar line edit alongside unable connect server errors terrible defaults error handling basic uiux perspective gauge long notebooklm podcast going based badly material spinner starts glitching small things lost sprawl assume permeates api cloud layers nt recent outages literally having exponential backoff",
    "sentiment": "negative",
    "key_phrases": [
      "catastrophic failure",
      "terrible defaults",
      "error handling"
    ]
  },
  {
    "text": "article op linked actually covers poison model thing cloudflare explicitly nt want served content actual real scientific content fake slop ai trained nt incorporate misinformation nt information website question",
    "sentiment": "negative",
    "key_phrases": [
      "poison model",
      "fake slop",
      "real scientific"
    ]
  },
  {
    "text": "thank responses scale account easily whip script prompt human defeats purpose",
    "sentiment": "negative",
    "key_phrases": [
      "defeats purpose",
      "whip script",
      "scale account"
    ]
  },
  {
    "text": "talking humanity driven ngo sure overall alignment companies built product public data turn charge default nt wrong absolutely love llms large companies enabled success nt trust instant start facing model collapse recursive ingestion correct formal term wo nt push narrative",
    "sentiment": "negative",
    "key_phrases": [
      "model collapse",
      "large companies",
      "public data"
    ]
  },
  {
    "text": "like google vs blackhat seos cloudflare team change things daily evolving ai labyrinth poisoning content",
    "sentiment": "negative",
    "key_phrases": [
      "ai labyrinth",
      "evolving ai",
      "blackhat seos"
    ]
  },
  {
    "text": "resources nt overcome limits legally available technological means scale required criminal botnets use techniques openai use cloudflare fights daily cloudflare knows ip addresses belonging data centers residential ip proxies world openai nt rent rotate addresses fast hide scale need going completely criminal",
    "sentiment": "negative",
    "key_phrases": [
      "criminal botnets",
      "cloudflare fights",
      "residential ip"
    ]
  },
  {
    "text": "approach detected immediately modern anomaly detection log analysis methods cloudflare certainly",
    "sentiment": "neutral",
    "key_phrases": [
      "anomaly detection",
      "log analysis",
      "cloudflare certainly"
    ]
  },
  {
    "text": "like couple thousand daemons scraping behavior modeled person computer opted game",
    "sentiment": "neutral",
    "key_phrases": [
      "behavior modeled",
      "person computer",
      "couple thousand"
    ]
  },
  {
    "text": "right state intent prevent misinformation odd attempting thwart ai bots mean s stop nt intention view stronger labyrinth",
    "sentiment": "negative",
    "key_phrases": [
      "prevent misinformation",
      "thwart ai bots",
      "labyrinth intent"
    ]
  },
  {
    "text": "like time large corporation incredibly illegal poisoning killing millions people nt stopped corporations past think developing sophisticated means hiding illegal access content essential product going stop benefit worth cost found shell company pay fall needed pass data company corporations tactics like nefarious purposes forever continue day little naive think ll let damaging slow honest data generated training data higher quality training data compared data scraped internet point little late honest need scrape think shaking hands entities china untouchable legally essentially impossible trace openai ways hurdles cloudflares attempts akin locking luggage airport deterrent stop committing crime opportunity slow motivated wo nt",
    "sentiment": "negative",
    "key_phrases": [
      "illegal poisoning",
      "hiding illegal",
      "higher quality"
    ]
  },
  {
    "text": "game anomaly detection pattern vary rate limiting ip addresses recycle residential example provided playing devils advocate learn",
    "sentiment": "neutral",
    "key_phrases": [
      "anomaly detection",
      "rate limiting",
      "ip addresses"
    ]
  },
  {
    "text": "actually nt detected random residential ips asn use sane request pattern hard scrape site",
    "sentiment": "negative",
    "key_phrases": [
      "random ips",
      "hard scrape",
      "request pattern"
    ]
  },
  {
    "text": "odd attempting thwart ai bots mean nt odd data likely model point wo nt models obviously worse assuming fake data small proportion overall training material subject result folks getting incorrect responses datas going released public line real data irrelevant s stop nt intention nt understand mean s stop poisoning crawler results d need global reach cloudflare automated vast scale",
    "sentiment": "negative",
    "key_phrases": [
      "ai bots fake",
      "poisoning crawler",
      "global reach"
    ]
  },
  {
    "text": "yea people pointed cloudflare errs public availability blocking people assuming bot detection omnipotent clearly tried scraping cloudflare site hard scrape larger site single ip patience",
    "sentiment": "negative",
    "key_phrases": [
      "bot detection",
      "public availability",
      "site scraping"
    ]
  },
  {
    "text": "poisoning attacks identified greater impact model performance volume data imply context helps understanding research shows large variance model learns certain document chunk token research shows certain data elements little negative value training myth nt know models work detailed mechanics large interpret promising approach right use ai models interpret details ai neural networks understand inner workings detail scale field matures likely types attacks effective",
    "sentiment": "neutral",
    "key_phrases": [
      "poisoning attacks",
      "model performance",
      "inner workings"
    ]
  },
  {
    "text": "actually worst case use pyautogui use computer open browser click access site want scrape",
    "sentiment": "negative",
    "key_phrases": [
      "worst case",
      "use pyautogui",
      "computer open"
    ]
  },
  {
    "text": "s true feel like ai future people like ai nt access website people wo nt accessing hardly browse web select specific cases toddlers growing ai probably hardly know web browser children wo nt web sites nt efficient format riddled ads seo hacking half content years time ai generated going browsing read ai ask write instantly s going thing nt board going lose big way eventually ai nt find exist good luck scraper protection",
    "sentiment": "negative",
    "key_phrases": [
      "ai generated",
      "nt efficient format",
      "lose big way"
    ]
  },
  {
    "text": "point allow new data data site owner nt consent replace old data model certainly training set wo nt improve model wo nt poison",
    "sentiment": "negative",
    "key_phrases": [
      "replace old",
      "data model",
      "wo nt"
    ]
  },
  {
    "text": "m sure talking course people random crap poison scrapers people wo nt reach cloudflare",
    "sentiment": "negative",
    "key_phrases": [
      "random crap",
      "poison scrapers",
      "cloudflare issues"
    ]
  },
  {
    "text": "mean human element assume necessary truly scale like site large company implement automatically regularly limited human input giving kneejerk interested learning like pyautogui selenium etc",
    "sentiment": "negative",
    "key_phrases": [
      "human element",
      "kneejerk reaction",
      "large company"
    ]
  },
  {
    "text": "ai nt reach site legit channels users bounce source feeds agent directly unlock shifting passive pages explicit feeds expose clean api graphql endpoint tag snippets charge token hit news outlets work testing aws data exchanges paypercall gateway substacks paid rss model gets fresh licensed facts ve seen folks bolt googles pair content license mosaic slots ads chat responses earn open endpoints nagging paywalls practice data lives structured monetized pipe cares raw html stays crawlerproofagents query paid readers notice sites ignore shift ghost towns cloudflare shields",
    "sentiment": "negative",
    "key_phrases": [
      "paid rss model",
      "paypercall gateway",
      "nagging paywalls"
    ]
  },
  {
    "text": "sorry bothered said nt small proportion training data impact attempted explain",
    "sentiment": "negative",
    "key_phrases": [
      "small proportion",
      "training data",
      "impact attempted"
    ]
  },
  {
    "text": "m saying worst case easiest case spoof google bot crawler normal requests pretty sure websites want google yeah",
    "sentiment": "neutral",
    "key_phrases": [
      "google bot",
      "worst case",
      "normal requests"
    ]
  },
  {
    "text": "said nt small proportion training data impact said small fake information provided cloudflare nt obviously worse product owners nt immediately identify poisoned subtly worse",
    "sentiment": "negative",
    "key_phrases": [
      "poisoned data",
      "small proportion",
      "worse product"
    ]
  },
  {
    "text": "d tool use create illustrations like recently ve seen researchers adopt style illustration present architectural view method approach visuals clean professional visually appealing perfect research papers presentations ve tried replicating style nt able achieve level quality aesthetics suggest tools software commonly create research illustrations m particularly interested tools suitable academic technical diagrams capable producing highquality publicationready visuals flexible custom styling layouts recommendations greatly appreciated check illustration",
    "sentiment": "neutral",
    "key_phrases": [
      "research papers",
      "visually appealing",
      "academic technical"
    ]
  },
  {
    "text": "sadly powerpoint great vector graphics easy drag group elements configurable snapto guides custom shapespatterns layering like photoshop powerpoint",
    "sentiment": "positive",
    "key_phrases": [
      "vector graphics",
      "drag group",
      "custom shapes"
    ]
  },
  {
    "text": "ve varying levels success pgftikz inkscape ms powerpoint google drawings know people use adobe illustrator",
    "sentiment": "neutral",
    "key_phrases": [
      "varying levels",
      "google drawings",
      "adobe illustrator"
    ]
  },
  {
    "text": "specific tool use going important comfortable working having produce scalable vector images thinking specific points need illustration getting long tooth centered presenting statistics tuftes visual display quantitative information great read thinking information try convey figure suggest like powerpoint overall blocksystems architecture diagrams libreoffice impress works produce svgepsanything jpg",
    "sentiment": "positive",
    "key_phrases": [
      "vector images",
      "visual display",
      "quantitative information"
    ]
  },
  {
    "text": "comic sans font example certainly interesting choice m sure d personally choose technicalacademic diagrams people like guess need liveedit latex equations block diagrams like boxesarrows pdf export interested vexlio developer",
    "sentiment": "neutral",
    "key_phrases": [
      "latex equations",
      "block diagrams",
      "pdf export"
    ]
  },
  {
    "text": "p tabular dl model tabm python package hi colleagues recently published python package tabm simple powerful dl architecture solving predictive tasks tabular data classification regression etc nutshell tabm efficiently imitates ensemble mlps image basically means tabm power ensemble time remains practical scalable recent highlights tabm successfully kaggle including winning solutions package provides pytorch implementation tabm pytorch layers functions building custom tabmlike models installation pip install tabm paper package colab example tabm model illustration",
    "sentiment": "positive",
    "key_phrases": [
      "tabm python",
      "dl architecture",
      "kaggle solutions"
    ]
  },
  {
    "text": "d draggan going viral image models remember impressed saw demo videos years nt reached level popularity expected natural language nt involved customized image manipulation features useful methough m expert active user domain workflow diffusionllmbased image models",
    "sentiment": "neutral",
    "key_phrases": [
      "image models",
      "demo videos",
      "diffusionllmbased"
    ]
  },
  {
    "text": "couple reasons head gans image generators useful interactive stuff lack fidelity stability ldms hype concentrated s fact draggan basically fancy photoshop plugin cute idea sure scope tool pretty limited nt expect attract kind mass appeal wellknown models",
    "sentiment": "negative",
    "key_phrases": [
      "lack fidelity",
      "pretty limited",
      "fancy photoshop"
    ]
  },
  {
    "text": "d fluent modifyingdesigningimproving models fluency mean read paper problem implement techniques mentioned building scratch paper guidance absence code modifying existing models having idea able translate designing new architectures modifying existing models improving models think people like phil wang prolific reproducing papers improving m curious know experience click unlocked ability productive things suspect boring answer reproduce papers bro hoping learn peoples experiencejourney guys specific insighttricks useful know like maybe good workflow good pipeline makes productive niche insight designingmodifyingimproving models people nt usually talk etc",
    "sentiment": "positive",
    "key_phrases": [
      "improving models",
      "designing new",
      "reproducing papers"
    ]
  },
  {
    "text": "finally started click actually started building stuffeven hacky halfworking way trying implement toy version passively reading nt work dig layer module causing issue s real learning happens helps reference repos clean wellannotatedgives mental map things structured tip nt copy run code try swap new loss function tweak architecture breaks s kinda tweak confidence",
    "sentiment": "positive",
    "key_phrases": [
      "real learning",
      "reference repos",
      "mental map"
    ]
  },
  {
    "text": "s good advice thank sort unfortunate expected feel like domain specific type architecture s bag tricks learn implementing tweaking experimenting models entirely different model sort learn anew bag tricks needed seemingly means need pour lot time working kind model want levels like phil wang reality guess nowadays underlying techniques overlaps lots popular models attention diffusion architectures llm knowledgeintuition gain working models highly transferable know repos resources good bag tricks different types models people accumulated sadly guess intuition models hard words",
    "sentiment": "positive",
    "key_phrases": [
      "domain specific",
      "bag tricks",
      "transferable know"
    ]
  },
  {
    "text": "sorry m wrong highly suspect bot promoting site mentioned like user messages site account created month ago lol",
    "sentiment": "negative",
    "key_phrases": [
      "bot promoting",
      "site mentioned",
      "account created"
    ]
  },
  {
    "text": "nt know bag tricks having strong foundation think achieve ml need able deep dive chosen area draw areas makes sense data science spectrum people crawling space finding truly novel tough unnecessary shop models like buying parts hardware store specialization interactive intelligence ml compared data scientists focus believe able broader view individuals participating grid search knowledge broad shallow enjoy adversarial networking mixture experts etc considering deal brining life experimentation models pretty quick dirty days want know hyperparameters sensitive data task selected benchmarking think approach going deep dive models suggest mastering filtering noise capacity constraints nt know way learn know years study",
    "sentiment": "neutral",
    "key_phrases": [
      "deep dive",
      "data science",
      "grid search"
    ]
  },
  {
    "text": "outsider ended tangential space software dev couple ml infra companies way actually clicked inner drive chosen area respect tried quit assume experiencing new dunningkruger mind kept coming types situations described unrelated disciplines formally dug field unrelated fields especially comes viewing source said interactive intelligence drew programming place tool makes tools help people resonates taking time concrete recommendations taking early steps making things concrete high signal reproducible work solid textaudiovisual resources things helped cross line m base worries",
    "sentiment": "positive",
    "key_phrases": [
      "inner drive",
      "concrete recommendations",
      "interactive intelligence"
    ]
  },
  {
    "text": "newton invented calculus understand physics loved math respect work data scientists think forest trees best people aiml come disciplines outside cs bring unique insight half interactive intelligence software engineering algorithm nt work systems expected needs time data science friends necessarily concerned high signal reproducible work seed random variables clarify seeking trying publish trying build text gpt supposed best writing nt found good ai visuals lol recently realized crossed line boss gave visible complex technically challenging projects fortune simultaneously warton fellow tell project novel probably dod funding willing introductions pretty good signal better leetcode let merge sort s important lol long",
    "sentiment": "neutral",
    "key_phrases": [
      "data science",
      "interactive intelligence",
      "signal reproducible"
    ]
  },
  {
    "text": "d uoft phd ranking terms academia prestige future prof positions place uoft ml phd better roi american school uiuc georgia tech ut austin uwash etc recognition considering advisors equivalent uoft phd fare oxbridge dphil days",
    "sentiment": "neutral",
    "key_phrases": [
      "phd ranking",
      "american school",
      "prof positions"
    ]
  },
  {
    "text": "supervisor fit personal motivation topic matter institution university reputation imperfect proxy research strengths networking supervisor guidance ll receive",
    "sentiment": "neutral",
    "key_phrases": [
      "supervisor guidance",
      "personal motivation",
      "imperfect proxy"
    ]
  },
  {
    "text": "toronto produced respectable successful names ml applications biggest example hinton recently won nobel prize physics breakthroughs anns worries academic prestige look departments best specifically",
    "sentiment": "positive",
    "key_phrases": [
      "respectable names",
      "nobel prize",
      "academic prestige"
    ]
  },
  {
    "text": "site good source seeing phd institution interacts hiring uoft good lots professors uoft near mit stanford berkeley cmu raw numbers list normalized number graduates unfortunately basically par georgia tech",
    "sentiment": "neutral",
    "key_phrases": [
      "good source",
      "phd institution",
      "near mit"
    ]
  },
  {
    "text": "cents m uoft ml phd people agree schools listed toronto virtually equivalent agree advisor topic etc matters worth noting going funding problems stuff canada insulated",
    "sentiment": "neutral",
    "key_phrases": [
      "ml phd people",
      "virtually equivalent",
      "funding problems"
    ]
  },
  {
    "text": "uoft ml phd student recognition university close zero bearing comes offered profship best work phd recommendation phd supervisor important aspects instead university recognition recognition professor matters lot university uoft people like stephen cook geoff hinton point recommendation ve landed place d hope",
    "sentiment": "positive",
    "key_phrases": [
      "phd recommendation",
      "uoft people",
      "best work"
    ]
  },
  {
    "text": "uoft vector institute known globally ai researchers programs mentioned oxfordcambridge realistically wo nt help quality researchsupervisor biggest impact opportunities post graduation",
    "sentiment": "negative",
    "key_phrases": [
      "ai researchers",
      "won't help",
      "post graduation"
    ]
  },
  {
    "text": "toronto school aiml atm hostile place graduate students particularly international students",
    "sentiment": "negative",
    "key_phrases": [
      "hostile place",
      "graduate students",
      "international students"
    ]
  },
  {
    "text": "curious specializing explored s available uoft terms research opps m debating msc pm s taking grad level courses stanford loving want focus causal reasoning neurosymbolic methods enhance performance generative tasks",
    "sentiment": "positive",
    "key_phrases": [
      "causal reasoning",
      "neurosymbolic methods",
      "grad level courses"
    ]
  },
  {
    "text": "minor nitpick hinton studied uoft phd university edinburgh course lot phd students uoft went cool stuff",
    "sentiment": "neutral",
    "key_phrases": [
      "phd students",
      "uoft went",
      "cool stuff"
    ]
  },
  {
    "text": "hinton taught sutskevar bunch famous ai researchers studied toronto hinton d years ago best place studying deep learning today m sure probably tier",
    "sentiment": "positive",
    "key_phrases": [
      "studying deep",
      "best place",
      "ai researchers"
    ]
  },
  {
    "text": "ai nt effected group historically excluded stem careers postcolonial country funding types programs specifically help communities dried worst elements society emboldened purge harass universities chance avoid lateral position canada",
    "sentiment": "negative",
    "key_phrases": [
      "historically excluded",
      "worst elements",
      "postcolonial country"
    ]
  },
  {
    "text": "nt know goals guide decision uoft respected know answer academia u t healthy percentage phds continuing tenured positions track end pay attention schools connected industry s important realize companies generally build connections universities people advisors past students help personal connection gives leg standard recruiting efforts connecting advisor important interest topic wo nt need genuine interest nt want burn advisor connect important position help process outside academia accepted",
    "sentiment": "neutral",
    "key_phrases": [
      "personal connection",
      "industry connections",
      "academic track"
    ]
  },
  {
    "text": "confidence decision universities ve listed highly respected ml concerns variance individual researchers institution universities worth thinking carefully work city matches interests ll spending years growing roots friends connections worth thinking lifestyle factors",
    "sentiment": "neutral",
    "key_phrases": [
      "highly respected",
      "individual researchers",
      "lifestyle factors"
    ]
  },
  {
    "text": "picking phd institutions magazine rankings rethink motivation phd ml researchers nowadays went school irrelevant possible head lecunparis silveralberta hintonedinburgh schmidhubertum bengiomcgill hassabiucl best research fit magazine ranking tells",
    "sentiment": "negative",
    "key_phrases": [
      "phd institutions",
      "magazine rankings",
      "research fit"
    ]
  },
  {
    "text": "agree w u think taking kind extreme opinion subject people listed like le cun etc literally kind institutes institutes like cmu regularly produce le cunish people relying rankings definitely optimal think profuni matrix university rankings misleading",
    "sentiment": "negative",
    "key_phrases": [
      "extreme opinion",
      "misleading rankings",
      "university rankings"
    ]
  },
  {
    "text": "uni big labs publish instead looking best labs field want pick publishes best field example wants research causal inference ml berkeley mit levine abeel tedrake insane publishing output rl robotics pushing rankings better labs causality columbia harvard ethz mpi",
    "sentiment": "neutral",
    "key_phrases": [
      "best labs field",
      "causal inference",
      "publishing output"
    ]
  },
  {
    "text": "nt think taking extreme stance saying pick lab advisor fits best want person field obviously lot people s going cmu berkeley mit stanford lot people nt ranking actually know want research perspective note think person influential lecun ml coming cmu ones thinking",
    "sentiment": "neutral",
    "key_phrases": [
      "lab advisor",
      "research perspective",
      "lecun ml"
    ]
  },
  {
    "text": "okay s fair nt talking undergrad nt think research career going depend taught basic calc intro cs undergrad haha",
    "sentiment": "negative",
    "key_phrases": [
      "research career",
      "basic calc",
      "intro cs"
    ]
  },
  {
    "text": "d applicability biomedical based aiml phd aiml fields hey year phd student biomedical program labs interested studies effectively use aiml enhance drug discovery development process current limited knowledge coding experience r little c pi told d happy join group wonder applicability niche expertise having phd biomedical focused aiml allow possibility hired finance aiml aiml research big tech applicable big pharmabiomed startup research thanks insights",
    "sentiment": "positive",
    "key_phrases": [
      "biomedical aiml",
      "drug discovery",
      "phd student"
    ]
  },
  {
    "text": "ve number biomedical aiml projects including generative small molecules drug discovery microscopy image analysis amino acid sequence encoding function structure prediction recruiters messaging roles non biomedical fields meta example recently reached improve ad recommendations ml",
    "sentiment": "neutral",
    "key_phrases": [
      "biomedical aiml",
      "image analysis",
      "ml recommendations"
    ]
  },
  {
    "text": "phd biofocused ml topfive uni world phd places interviewed biotechs got approached companies different domains people cohort went fintechs imo depends pitches work networking phds",
    "sentiment": "neutral",
    "key_phrases": [
      "phd biofocused",
      "different domains",
      "people cohort"
    ]
  },
  {
    "text": "m undergrad student working biomedical computer vision probably wacv paper published year phd necessary research role field",
    "sentiment": "neutral",
    "key_phrases": [
      "biomedical computer",
      "vision paper published",
      "phd research role"
    ]
  },
  {
    "text": "d request career advice ml phd non hot topic m currently phd student machine learning working research topic nt considered hot current academic industrial landscape despite ve managed publish lead author icml neurips twice ecml coauthored publications ecai ve noticed phd students stronger publication records trendier areas makes question competitive current job marketespecially given wave layoffs increasing demand specialized expertise industry said strong foundation core ml deep learning llms llms nt direct focus phd research given m trying realistically assess current chances landing demanding highquality job industry research phd improve chances goal fanng d greatly appreciate feedback edit research focuses",
    "sentiment": "negative",
    "key_phrases": [
      "phd student",
      "current job",
      "strong foundation"
    ]
  },
  {
    "text": "imagine computer vision expert publish lot hot topic custom descriptors feature matching augmented reality pity unfortunate souls trying convolutional networks work dead end previous century approach gaming videocards poor things",
    "sentiment": "negative",
    "key_phrases": [
      "hot topic",
      "dead end",
      "poor things"
    ]
  },
  {
    "text": "similar credentials years ago pubs icml neurips focusing topics like high dimensional statistics numerical linear algebra theory stuff short postdoc deep learning language models adjacent theory managed work pulished fast forward m faang working llm applied research point competent deeply technical stuff research relevant latest hot topics need find way smooth transition credentials",
    "sentiment": "negative",
    "key_phrases": [
      "high dimensional",
      "deep learning",
      "smooth transition"
    ]
  },
  {
    "text": "intern network research scientist jobs competitive phd mit famous advisor strong industry connections",
    "sentiment": "positive",
    "key_phrases": [
      "research scientist",
      "strong industry",
      "mit famous"
    ]
  },
  {
    "text": "ve noticed phd students stronger publication records lead author papers good conferences workshop sessions posters trying understand consider stronger record",
    "sentiment": "neutral",
    "key_phrases": [
      "phd students",
      "publication records",
      "conference sessions"
    ]
  },
  {
    "text": "lot competitive poor sobs graduating coltstocfocs papers code data papers websites demos nt industry start leetcoding reach connections brownbag talks orgs faang d love pictures talks tweet academia advisors letter important reaching connections important send cold emails shame fearful saving face year market said lot academia hiring freeze right including postdocs",
    "sentiment": "negative",
    "key_phrases": [
      "poor sobs",
      "hiring freeze",
      "cold emails"
    ]
  },
  {
    "text": "good bad thing people gotten faang deepmind fair etc lot example coworkers lab work deepmind grand total neurips icml iclr papers publication record strong ai conference publications vs matter course papers super wellcitedwellknown paper said big problems going face research direction teams faang probably foremost sure people hiring studying similar things thought deeply currently exploringresearching x ai conference publications peer review noisy getting worse year anyways second networking people work companies interned lab alumni working faculty known industry think best advice find way connect clear expertise anomaly detection popularcurrent try intern publish faculty industry connections",
    "sentiment": "neutral",
    "key_phrases": [
      "deepmind papers",
      "ai conference",
      "peer review"
    ]
  },
  {
    "text": "famous advisor mean famous current hot topic interests recently shown promising ml applications nt consider professors working field famous language model space example",
    "sentiment": "neutral",
    "key_phrases": [
      "famous advisor",
      "ml applications",
      "language model"
    ]
  },
  {
    "text": "firstauthor publications icml neurips ecml unfortunately ecml generally considered midtier conference ve seen phd students firstauthor papers published toptier venues like neurips icml iclr kdd",
    "sentiment": "negative",
    "key_phrases": [
      "midtier conference",
      "firstauthor papers",
      "top tier venues"
    ]
  },
  {
    "text": "lot competitive poor sobs graduating coltstocfocs papers sattire random ml people thread think colt similar stature stocfocs",
    "sentiment": "negative",
    "key_phrases": [
      "poor sobs",
      "competitive thread",
      "ml people"
    ]
  },
  {
    "text": "thank tips actually started leetcode recently given current situation ve solved problems stay competitive",
    "sentiment": "positive",
    "key_phrases": [
      "leetcode recently",
      "stay competitive",
      "given situation"
    ]
  },
  {
    "text": "ngl think ll d talk yue zhao usc jiawei han uiuc",
    "sentiment": "neutral",
    "key_phrases": []
  },
  {
    "text": "d argue anomaly detection falls sorta trendy need novel ways find wild flaws systems artifacts physical engineering projects etc depending subfield tied casual inference gotten popular recently nt strictly latest llm craze think d looking work anomaly detection modern tech",
    "sentiment": "neutral",
    "key_phrases": [
      "anomaly detection",
      "novel ways",
      "physical engineering"
    ]
  },
  {
    "text": "anomaly detection ml anomaly detection ml models areas honestly need like try compare people espically coming big labs collaborate help need focus quality research technical social skills great publicaiton record",
    "sentiment": "neutral",
    "key_phrases": [
      "anomaly detection",
      "ml models",
      "social skills"
    ]
  },
  {
    "text": "worried classic problem useful industry track record thing need apply reach previous lab mates referrals source big tech research intern papers neurips icml iclr",
    "sentiment": "neutral",
    "key_phrases": [
      "classic problem",
      "big tech",
      "research intern"
    ]
  },
  {
    "text": "anomaly detection ml thanks feedback ill stay focused continue preparing standard interviews like leetcode system design",
    "sentiment": "positive",
    "key_phrases": [
      "anomaly detection",
      "ml thanks",
      "leetcode system"
    ]
  },
  {
    "text": "nt sure jobs gets renamed fast think llm safety engineers involved cover lot broader domain ryt think demand monitoring merrics team companies main thing phd teaches research applicable ground domain",
    "sentiment": "neutral",
    "key_phrases": [
      "llm safety",
      "demand monitoring",
      "phd teaches"
    ]
  },
  {
    "text": "completely anecdotal reason ask friends know actual theory heavy phd primarily published focsstoc",
    "sentiment": "neutral",
    "key_phrases": [
      "actual theory",
      "heavy phd",
      "published focsstoc"
    ]
  },
  {
    "text": "anecdotal bruh preprint analyzing faculty hiring cs subfields like subscribe substack s course ll smart said theoreticians struggle market theoryfocused phd students significantly fewer faculty offers nontheoryfocused ones similar quality nt believe nt care",
    "sentiment": "negative",
    "key_phrases": [
      "faculty hiring",
      "struggle market",
      "theory focused"
    ]
  },
  {
    "text": "know theorists hate need impress nontheorists practical implications work enable tldr website paper good website ask friends feedback release slides tutorials etc given organize workshopstutorials ask advisor reach schools particularly interested showcase independence thought advisor coauthors leetcoding lot randomness faculty job market industry good option embrace hustle stay healthy easier musicians creatives trying signed label",
    "sentiment": "positive",
    "key_phrases": [
      "practical implications",
      "release tutorials",
      "job market industry"
    ]
  },
  {
    "text": "d understanding ddim accelerated sampling case hello going ddim paper queries sampling accelerated appendix authors assume forward decomposed forward decomposition backward backward decomposition tau subsequence timesteps thing want point index start right saying look decomposition forward timesteps subsequence directly writing timesteps subsequence write mimic reverse write timesteps subsequence timesteps subsequence write explaination looks good intuitive sense example write decomposition intutition nt come example term backward fifth nt sense explain backward decomposition work note nt know correct place ask type questions felt subs suited thanks",
    "sentiment": "neutral",
    "key_phrases": [
      "forward decomposition",
      "backward decomposition",
      "timesteps subsequence"
    ]
  },
  {
    "text": "r new approach aidriven rd sharing generative reasoning framework community stresstesting stochastic kernel mixture productionready framework generating synthetic optimization landscapes critique days ago briefly posted early version conceptual prompting framework called simulated parallel inferential logic deleted formatting issues reasoning canvas old iteration framework available ve developed automated tool implement methodology ve named cognitive forge metaprompting framework creates bespoke multiperspective reasoning engines tackle complex problems plan post framework cognitive forge prompt howto guide github tomorrow use hope valuable tool community different standard multiagent systems forge operates different principle agentic systems instead static team predefined agents coder agent dynamically generates bespoke team",
    "sentiment": "positive",
    "key_phrases": [
      "generative reasoning",
      "stochastic kernel",
      "cognitive forge"
    ]
  },
  {
    "text": "biggest gap verifying kernel mixture actually spans useful function families instead neat math stab training incontext optimizers diversity dies moment latent vae bottleneck shrinks shipping d run leaveoneregionout coverage test sample tens thousands z codes cluster gradient spectra flag clusters fewer n members manual inspection numerical stability adaptive nugget smart ll hit nasty spikes peak base kernels overlap aggressively adding soft floor lengthscale sampling kept condition numbers sane killing shape variety think dataset watermarking earlymodels memorize generators quirks inject salted hash lowmagnitude coefficients track leakage downstream ve leaned weights biases lineage ray serve scaling mosaic need quick monetization experiments ops",
    "sentiment": "negative",
    "key_phrases": [
      "kernel mixture",
      "latent vae",
      "numerical stability"
    ]
  },
  {
    "text": "p opensource scaled automated paired testing bias nyc proven impact paired testing identical requests varying factor exposed systemic discrimination housing hud audits fair housing act hiring applications proved racial bias problem manual testing nt pace modern discrimination ai systems human bureaucracies hybrid decision systems current solutions fail traditional audits artificially limited scale ai governance tools look code realworld behavior human system audits easily gamed temporary compliance fix tests decision system ai models government offices hr fully automated paired testing millionscale internal access needed measures real outputs turns resistance proof guilt public domain findings accountability engine run massive tests hiring algorithms",
    "sentiment": "negative",
    "key_phrases": [
      "systemic discrimination",
      "racial bias",
      "ai governance"
    ]
  },
  {
    "text": "d relationship metas fair super intelligence labs like google brain deepmind previously nt point setting new ai lab meta maybe related semiacquisition scale ai creating group dedicated alexandr wang nt merger google brain deepmind suggest better split resources ai war possible feud",
    "sentiment": "negative",
    "key_phrases": [
      "ai war",
      "feud possible",
      "scale ai"
    ]
  },
  {
    "text": "yann lecuns fairs director chief ai scientist meta focus world models critical comments transformers maybe fair super intelligence labs head different directions researchwise",
    "sentiment": "neutral",
    "key_phrases": [
      "ai scientist",
      "world models",
      "super intelligence"
    ]
  },
  {
    "text": "yes turf war compute fair work architectures nt scaleups autogressive models",
    "sentiment": "neutral",
    "key_phrases": [
      "turf war",
      "compute fair",
      "autogressive models"
    ]
  },
  {
    "text": "semiacquisition scale ai metas ai future plus leveraging alexandr wangs expertise strategic stay competitive",
    "sentiment": "positive",
    "key_phrases": [
      "ai future",
      "leveraging expertise",
      "stay competitive"
    ]
  },
  {
    "text": "right long run think s lot juice left autoregressive models especially coding space formal verification rapidly test hypotheses experiments cloud inference time",
    "sentiment": "neutral",
    "key_phrases": [
      "autoregressive models",
      "formal verification",
      "test hypotheses"
    ]
  },
  {
    "text": "d classical ml prediction preventing data leakage time series process data working process industry attempted making soft sensors given continuous industrial process data points recorded historian minute try predict outcome applying classical ml methods xgboost use case demands model works like software sensor continuously gives numerical prediction output process time series forecast eg looking distant future predicting immediate outcome question shuffling data leads data leakage neighbouring data points contain similar information contains temporal information shuffling model extremely poor generalise fellow practitioners suggestions dealing ml time series related data leakage thanks advance kind sharing",
    "sentiment": "neutral",
    "key_phrases": [
      "classical ml",
      "data leakage",
      "time series"
    ]
  },
  {
    "text": "shuffling model extremely poor generalise bit confusing sentiment think clarifying help solve problem sounds like saying trainingvalidation loss figures better leaky data certainly situation choice allow leaky data performant model trained leaky data poor model trained wellformed data poor model stop certain situations allowing answer sheet taking exam nt excited good auc numbers training leaky data fictitious ground assessment models performance outofsample testing time series problems means holdout test set temporally training data models perform fact properly heldout test set seeing better performance leaky training data tell fascinated",
    "sentiment": "negative",
    "key_phrases": [
      "poor generalise",
      "leaky data",
      "outofsample testing"
    ]
  },
  {
    "text": "work sports deal constantly predicting near future xgboost data temporal time series m exactly sure mean shuffling model extremely poor generalise mean single pastfuture split benchmark poor comparing model trainedevaluated leaky way going look worse becuase model cheating general approach model development use stepforward cross validation standard time series stuff instead splitting data n random folds split n sequential chunks training past testing chunk simulates production environment regularly retraining generally good idea line work data points come groups respect days games custom basecrossvalidator s issue use timeseriessplit technically time series stepforward cv optimizing xgboost hyperparameters worth optimizing training schedule retrainsplit",
    "sentiment": "negative",
    "key_phrases": [
      "poor generalise",
      "leaky way",
      "cross validation"
    ]
  },
  {
    "text": "elaborate exactly shuffling data ways respect chronological order typically train past predict future matter shuffling",
    "sentiment": "neutral",
    "key_phrases": [
      "data shuffling",
      "chronological order",
      "train predict"
    ]
  },
  {
    "text": "temporal information process nt removed example imagine continuous production process desires continuous prediction output temperature based input features data days available data shuffled model suffer leakage sees data jan validatespredicts jan nt shuffle data janfeb training predicting march model generalise production",
    "sentiment": "negative",
    "key_phrases": [
      "data leakage",
      "model suffers",
      "continuous prediction"
    ]
  },
  {
    "text": "like model sees points days row features predicts day kind split like m little confused predictions minutes example months second example",
    "sentiment": "neutral",
    "key_phrases": [
      "model sees",
      "little confused",
      "training time"
    ]
  },
  {
    "text": "oh random shuffling big nono time series data sure having data points past predict future point exactly probably based exact problem",
    "sentiment": "negative",
    "key_phrases": [
      "time series",
      "random shuffling",
      "predict future"
    ]
  },
  {
    "text": "yes m aware nt random shuffling hoping specific ways shuffle data let generalise better leakage neighbouring data points",
    "sentiment": "negative",
    "key_phrases": [
      "data leakage",
      "neighbouring data",
      "random shuffling"
    ]
  },
  {
    "text": "m sure going crazy generalization gains shuffling data sounds like trying model continuousregression problem outputs wo nt change information predicting output correct",
    "sentiment": "negative",
    "key_phrases": [
      "generalization gains",
      "shuffling data",
      "continuous regression"
    ]
  },
  {
    "text": "looking start game d look friends master start game working time pepper check achoo",
    "sentiment": "neutral",
    "key_phrases": []
  },
  {
    "text": "p created opensource tool analyze m medical ai papers pubmed hey ve working personal project understand ai actually medical research hype thought find results interesting analyzing nearly million pubmed papers use ai methods found intersting results classical ml dominates despite deep learning hype traditional algorithms like logistic regression random forests account medical ai research algorithm preferences medical condition different health problems gravitate specific algorithms transformer takeover timeline exact point transformers overtook lstms medical research built interactive dashboard search medical condition algorithms researchers track algorithm usage evolved time distribution classical ml deep learning llms trickiest parts filtering false positives like gan",
    "sentiment": "positive",
    "key_phrases": [
      "opensource tool",
      "medical ai",
      "classical ml"
    ]
  },
  {
    "text": "love surfacing adoption patterns instead hype transformers quick win linking disease keywords umls ids diabetes dm roll metamap scispacy lines cut noisy synonyms gangiant axonal neuropathy clash add regex surrounding words like network neuropathy weight title abstract differentlyfalse positives drop fast exposing cleaned dataset tiny rest endpoint let folks pull numbers straight r jupyter metaanalysis similar dimensions data dump semantic scholars api mosaic thing let sprinkle targeted ads opened dashboard public monetization stays optional change mind cool hard numbers backing intuition classical ml rules clinic",
    "sentiment": "positive",
    "key_phrases": [
      "adoption patterns",
      "quick win",
      "semantic scholars"
    ]
  },
  {
    "text": "possible applying project google scholar want find trend applying mlai financeinsurance field",
    "sentiment": "neutral",
    "key_phrases": [
      "applying mlai",
      "google scholar",
      "finance insurance"
    ]
  },
  {
    "text": "nice project thanks sharing use pubmed api retrieval indexed btw link pubmed articles broken",
    "sentiment": "neutral",
    "key_phrases": [
      "nice project",
      "pubmed api",
      "broken link"
    ]
  },
  {
    "text": "curious achieved groupings got list predefined algorithms searched synonyms generated topics discussed paper",
    "sentiment": "neutral",
    "key_phrases": [
      "predefined algorithms",
      "generated topics",
      "discussed paper"
    ]
  },
  {
    "text": "thanks sharing ill classical ml dominating lot explainabilityinterpretability things like preponderance tabular data medicine ehrs unlike imaging nt need expert manual labelling labour intensive potentially expensive work prepare theme ve seen fair ml research healthcare people clinical background things like rf logreg etc accessible dl",
    "sentiment": "positive",
    "key_phrases": [
      "classical ml",
      "clinical background",
      "fair ml research"
    ]
  },
  {
    "text": "inference model use decide best inference model upcoming preprint based title abstract \u0ca1 \u0296 \u0ca1",
    "sentiment": "neutral",
    "key_phrases": [
      "inference model",
      "best model",
      "upcoming preprint"
    ]
  },
  {
    "text": "thanks excellent suggestions umls d mapping definitely solve synonym problem look nt thought scispacy makes perfect sense agree regex efficient current method require filtering instead relying search api require refactoring system definitely plan long term poc wanted simple quickly demand tools like",
    "sentiment": "positive",
    "key_phrases": [
      "excellent suggestions",
      "umls d mapping",
      "scispacy makes sense"
    ]
  },
  {
    "text": "ill soon publish blog post explaining process think interesting tldr dataset obtained directly pubmeds official api scraping involved system constructs boolean queries combining medical problems algorithm synonyms queries pubmed api proper rate limiting delays requests results cached hit rate minimize api calls historical data permanently cached current year data cached hour",
    "sentiment": "positive",
    "key_phrases": [
      "pubmed api",
      "boolean queries",
      "rate limiting"
    ]
  },
  {
    "text": "data obtained directly pubmeds official api m synonyms aggregate results blacklist terms avoid false positives example query looks like breast cancer svm breast cancer support vector machine stroke volume monitoring reviewpublication type ofc ideal large volumes data fairly accurate general trends",
    "sentiment": "neutral",
    "key_phrases": [
      "svm breast",
      "large volumes",
      "false positives"
    ]
  },
  {
    "text": "umls mapping onthefly disambig stay lightweight push thin inference layer instead ripping current search stack run scispacys entitylinker small fastapi microservice cache output duckdb hit heavy lift later calls instant gan vs neuropathy clash twostage filter works cheap string check gan title true scan tokens network neuropathy saw false positives drop touching rest codebase exposing numbers easier rest suite slap csv endpoint dumps cached duckdb table folks wget pandas ve run similar dashboards supabase handled auth retool gave quick ui pulse reddit kept beta testers flowing touching marketing tiny cleanup like makes value pop immediately",
    "sentiment": "neutral",
    "key_phrases": [
      "entity linker",
      "fastapi microservice",
      "duckdb cache"
    ]
  },
  {
    "text": "yes search api advanced allows chain multiple operators filter based paper type year etc searches relevant terms titles abstracts ner fulltext accurate pubmed milion papers computationally challenging tested manually relevant methods usually described abstract title keywords decided tradeoff worth",
    "sentiment": "neutral",
    "key_phrases": [
      "search api advanced",
      "paper type year",
      "computationally challenging"
    ]
  },
  {
    "text": "d recommended preparation material ml interviews hi gathering interview preparation tools ml research positions people job market recently recommend find relevant resources missing interviewquery devinterview aiofferly mad",
    "sentiment": "neutral",
    "key_phrases": [
      "ml interviews",
      "job market",
      "interview preparation"
    ]
  },
  {
    "text": "stuff looks good time applying bunch great resources youtube practice interviews questions change lot probably dated definitely worth looking",
    "sentiment": "positive",
    "key_phrases": [
      "great resources",
      "practice interviews",
      "worth looking"
    ]
  },
  {
    "text": "deep learning interviews previously posted free arxiv current iteration aimed optimization network design specific applications aiming specific subfields computer vision llms etc",
    "sentiment": "neutral",
    "key_phrases": [
      "deep learning",
      "network design",
      "computer vision"
    ]
  },
  {
    "text": "interviewed faang research science internships imo glance aiofferly questions relevant different different roleslevels",
    "sentiment": "neutral",
    "key_phrases": [
      "research science",
      "faang internships",
      "different roles"
    ]
  },
  {
    "text": "ones listed glance yes ill probably look detail want rankings ill respond later",
    "sentiment": "neutral",
    "key_phrases": [
      "look detail",
      "want rankings",
      "respond later"
    ]
  },
  {
    "text": "yeap ones listed glance yes ill probably look detail want rankings ill respond later wow think help lot",
    "sentiment": "positive",
    "key_phrases": [
      "look detail",
      "want rankings",
      "help lot"
    ]
  },
  {
    "text": "p dfreg physicsinspired regularization method operates global weight distributions hi d like share recent preprint uploaded arxiv introducing dfreg new regularization framework neural networks inspired density functional theory dft physics dfreg dfreg replaces local penalties like regularization dropout global constraint empirical weight distribution treats weights neural network statistical density introduces functional penalty encourages smooth nonpeaky weight distributions diverse wellspread parameter configurations structural regularity layers architectural changes stochastic perturbations required tested evaluated dfreg comparing dropout batchnorm metrics included test accuracy loss weight entropy histogram regularity fft convolutional filters notably trained batchnormfree resnets dfreg regularizer key findings dfreg matches outperforms dropout batchnorm",
    "sentiment": "positive",
    "key_phrases": [
      "physics inspired",
      "global weight",
      "density functional"
    ]
  },
  {
    "text": "d subreviewing neurips professor share assigned papers lab members ask subreview neurips realized agreeing actually reviewer guidelines q invite subreviewer help reviews subreviewers allowed conflicts interest properly checked reviewers officially system subreviewers able participate discussion critical phase review process little bit worried involved nt hand things academia people paper actually accepted practice think common professors review papers students like cases officially appointed subreviewer neurips nt allow instead giving professor review pass short normal accepted happen lab worry update thank let know wo nt trouble subreviewing s relief know wondering guidelines code conduct mean professors nt signing ghostwritten review credit form",
    "sentiment": "negative",
    "key_phrases": [
      "review process",
      "conflicts interest",
      "academia people"
    ]
  },
  {
    "text": "professor probably nt realise subreviewing allowed neurips allowed conferences probably nt decide check wo nt affect",
    "sentiment": "negative",
    "key_phrases": [
      "nt realise",
      "nt decide",
      "nt affect"
    ]
  },
  {
    "text": "fairly common occurence unfortunately doubt d trouble said qa guidelines outlines great",
    "sentiment": "negative",
    "key_phrases": [
      "fairly common",
      "doubt trouble",
      "qa guidelines"
    ]
  },
  {
    "text": "s big difference ghost writing review asking colleague student think paper",
    "sentiment": "neutral",
    "key_phrases": []
  },
  {
    "text": "believe advisor scrutinizing look subreviewer comments feel sorry authors limited knowledge research work surrounding review paper makes subreviewer constrained chances correct evaluation",
    "sentiment": "negative",
    "key_phrases": [
      "limited knowledge",
      "constrained chances",
      "feel sorry"
    ]
  },
  {
    "text": "ok great hear likely wo nt affect thank m surprised nt realize s case review neurips year \u30c4",
    "sentiment": "positive",
    "key_phrases": [
      "great hear",
      "neurips year",
      "case review"
    ]
  },
  {
    "text": "nt think completely understand mean mean got trouble professor knowing nt taken risk thought risky yes paperspreprints far coauthored professor",
    "sentiment": "negative",
    "key_phrases": [
      "trouble professor",
      "risky yes",
      "nt taken"
    ]
  },
  {
    "text": "ve previously subreviewed prof assigned subreviewer openreview different ml conference conference allowed subreviewers area chair knew reviewed guess authors nt know completely care conflict interest problem ac aware subreviewer assignment gives credit recognition subreviewer efforts invited reviewer following year nt know subreview previous year guess find weird case neurips explicitly nt allow subreviewing ghostwriting subreviewer assignment m surprised people casually blatantly ignore reviewer guidelines code conduct know review recognition nt mean feels like minor intellectual integrity issue elses writeup like happened class m pretty sure student accused plagiarism got ta program major complain wo nt waves interesting view intellectual integrity",
    "sentiment": "negative",
    "key_phrases": [
      "conflict interest",
      "ghostwriting subreviewer",
      "ignore reviewe"
    ]
  },
  {
    "text": "d path mid careermid aged mle ml research industry ve seen flavor questions phd join research lab slightly different question noncs phd decade ago failed faculty position bunch postdocs meandered fang jobs ds mle applied research job stats heavy ml bunch layoffs restructuring currently traditional mle role think recommendation systems ab tests metrics heart want research ve dabbled writing single author paper ml conferences time kinda hard job family etc manage pull neurips paper lets help entry card researchy ml job like research scientist research engineer ml lab competing ml phds multiple papers networks etc think nt lot time friends",
    "sentiment": "negative",
    "key_phrases": [
      "ml research",
      "faculty position",
      "layoffs restructuring"
    ]
  },
  {
    "text": "profile good role model guy phd math seemingly ml adjacent judging publication record researcher openai looks like engineer long started publishing seemingly working researchers google dm guess game plan company research help researchers",
    "sentiment": "neutral",
    "key_phrases": [
      "role model",
      "ml adjacent",
      "research plan"
    ]
  },
  {
    "text": "join company research nt phd late life wo nt pay anymore need making money life achievements like houseretirement phd making money years away want reenter academic race spit guarantee phd research lab position ml field crowded graduate ivy league tier publications stand anymore goodbye life sign",
    "sentiment": "negative",
    "key_phrases": [
      "phd research",
      "making money",
      "academic race"
    ]
  },
  {
    "text": "nt mention things importance based want ml research secretly wishing fang type position earn m year help answer question questions provide x table starting critical scenario based secretly wishing m salary saying want ml research s scenario s going tough impossible means tough trick publish conference icml neurips topic interest employer ll maximize chances seeing employer want tmlr fairly acceptable target options table nonfang companies engineering scientific labs desperately need people knows ml likely nt teams discussing latest novelties implementing latest architecture lunch work fairly reputed group germany researchers simplest version unet image classification",
    "sentiment": "negative",
    "key_phrases": [
      "ml research",
      "tough scenario",
      "maximize chances"
    ]
  },
  {
    "text": "best knowledge companies offer true rs role purely mainly publicationfocused ml competitive oneoff pub likely wo nt cut super big shot rest grant rs title effectively research engineer role bad lot work muddy costly publication ultimately important delivering good service line probably pretty blurry mles team working trendy topics worth sacrificing lot oneoff pub truly good number need open doors team change job switch want team academic lab nt grind step submission super familiar process discuss folks presumably date field sway gift funding compute resource job opportunity easy",
    "sentiment": "negative",
    "key_phrases": [
      "research engineer",
      "bad lot work",
      "open doors team"
    ]
  },
  {
    "text": "boss share results tweets people cite instead way work writing paper",
    "sentiment": "negative",
    "key_phrases": [
      "share results",
      "cite instead",
      "way work"
    ]
  },
  {
    "text": "predict recent neuripsiclricmlcvpr paper likely research internship maybe company like drop wifes friends d publications probably time position framing odd phd publish field dream hard",
    "sentiment": "negative",
    "key_phrases": [
      "research internship",
      "phd publish",
      "hard time"
    ]
  },
  {
    "text": "look startup strong research topic let explain work startup focus medical summarization days software engineering core idea deeply rooted research open questions allowed come task setup experiments m writing papier emnlp long process serves desire research actual programming interests",
    "sentiment": "positive",
    "key_phrases": [
      "strong research",
      "medical summarization",
      "open questions"
    ]
  },
  {
    "text": "yes research engineer adjacent research start proposing ideas papers ll good candidate research positions",
    "sentiment": "positive",
    "key_phrases": [
      "research engineer",
      "proposing ideas",
      "good candidate"
    ]
  },
  {
    "text": "p ml deployment deployed models firebase vertex ai m looking best practice clean cohesive deployment realtime data need design continuous retraining pipeline essence inferences update dashboard",
    "sentiment": "neutral",
    "key_phrases": [
      "ml deployment",
      "realtime data",
      "retraining pipeline"
    ]
  },
  {
    "text": "d computing attention scores long context llms m trying compute topk tokens yielding highest attention scores inference frameworks vllm plain huggingface transformers models m big terms parameters max huge terms context windows m tokens m face problems vllm access attention scores way missing feature implemented transformers need use gpu budget skyrockets gbs large inputs machine total gb vram output attention scores way solve use eager attention implementation makes unfeasible terms gpu requirements facing similar problem compute attention scores large inputs",
    "sentiment": "negative",
    "key_phrases": [
      "huge terms parameters",
      "gpu budget skyrockets",
      "large inputs machine"
    ]
  },
  {
    "text": "probably nt common vllm primarily inference framework research platform suspect asked thing flash attention need set m sure s wired transformers inject attention model fork code set property",
    "sentiment": "neutral",
    "key_phrases": [
      "inference framework",
      "flash attention",
      "inject attention"
    ]
  },
  {
    "text": "r transition matching scalable flexible generative modeling imo silent banger meta generalizing diffusion flow matching transition matching unified causal generation process",
    "sentiment": "positive",
    "key_phrases": [
      "generative modeling",
      "diffusion flow",
      "transition matching"
    ]
  },
  {
    "text": "r inferencetime scaling collective intelligence frontier ai tldr abmcts lets multiple frontier models work inference time outperforming model running benchmark new inferencetime scaling algorithm enables collective intelligence ai allowing multiple frontier models like gemini pro cooperate inspired power human collective intelligence greatest achievements arise collaboration diverse minds believe principle applies ai individual frontier models like chatgpt gemini deepseek remarkably advanced possessing unique strengths biases stemming training view valuable resources collective problemsolving abmcts adaptive branching monte carlo tree search harnesses individualities allowing multiple models cooperate engage effective trialanderror solving challenging problems single ai initial results benchmark promising abmcts combining current frontier",
    "sentiment": "positive",
    "key_phrases": [
      "collective intelligence",
      "frontier models",
      "inference time"
    ]
  },
  {
    "text": "d far llm pattern recognition good designed ml models llms getting better quickly like time new release comes moved faster anticipated great abstract code integrating systems etc find excellent data processing tasks machine learning code especially knows understands concepts able understand llm given wrong inefficient answer think day llms good perform ml model designed traditional processes example create model predicted outcomes center took months data exactly like needed system identify best transformation combinations features model architecture optimize performance wonder soon ill able feed records llm tell look records teach predict ill records want accurate predictions perform better model spent months",
    "sentiment": "positive",
    "key_phrases": [
      "pattern recognition",
      "integrating systems",
      "machine learning"
    ]
  },
  {
    "text": "work large tech company way way superior hoping years ve large teams set classifiers tons training data try label x happening digital media turns ask frontier llms exact question training data whatsoever performs classic ml classifiers ve invested completely changes game type work area workflow labelled data set samples iterate prompts llm classify samples acceptable pr serving llm classifier expensive need m classifications day distill llm generating silver labels m samples llm train deep learning model silver labels nt need training data anymore lot traditional tasks need evaluation data smaller",
    "sentiment": "positive",
    "key_phrases": [
      "large teams set",
      "completely changes game",
      "llm classify samples"
    ]
  },
  {
    "text": "certain parameter countcomputational level ml model trained specific task perform better llm describing principle free lunch theorem possible large language model replace job data scientist train model",
    "sentiment": "neutral",
    "key_phrases": [
      "large language model",
      "ml model trained",
      "free lunch theorem"
    ]
  },
  {
    "text": "wait m confused llm struggle simple maths point efficient detect calculator needed run calculator subroutine claiming feed matrix instances n features numerical categorical boom works better actually training supervised ml model specific task millions training instances surprising result true llm trained perform similar tasks mentioned good generating code train ml model provide research papers demonstrated behavior nt think training ml model complex basically y good applications complexity preparing data building features analyzing results",
    "sentiment": "positive",
    "key_phrases": [
      "llm struggle",
      "simple maths",
      "training ml"
    ]
  },
  {
    "text": "current architecture llm perform task d need rewrite model weights far m aware tech exist kinda like asking fusion tech commercially viable rough idea d nt demonstrated nt built unforeseen obstacles blocking total wild guess year range change dramatically new developments",
    "sentiment": "negative",
    "key_phrases": [
      "current architecture",
      "unforeseen obstacles",
      "new developments"
    ]
  },
  {
    "text": "feel like seeing basically area nlp specialized methods provide incremental gains flagship llm models point worth increased effort underperform llms entirely think people invested ton time learning finetune train ml models happy lot mlrelated subreddit like contingent poopooing efficacy llms insisting need finetune model sort similar shift previous classical ml methods deep learning happened years ago",
    "sentiment": "negative",
    "key_phrases": [
      "incremental gains",
      "underperform llms",
      "finetune model"
    ]
  },
  {
    "text": "numerical data textual purely numerical data nt understand llm better simple tasks nt require complex model tasks signal processing computer vision etc nt sense tell llm write code ml model data transformation etc llm nt understand numerical data mess simple calculations mechanism suited nlp task maybe mixed data classification perfectly makes sense outperform",
    "sentiment": "negative",
    "key_phrases": [
      "nt understand llm",
      "simple tasks nt",
      "computer vision etc"
    ]
  },
  {
    "text": "makes lot sense cases apply data splitting tune prompt train set evaluate held set avoid overfitting prompt finetuning",
    "sentiment": "neutral",
    "key_phrases": [
      "data splitting",
      "avoid overfitting",
      "train set"
    ]
  },
  {
    "text": "totally insane trying model m working feeding couple records time trying predict target eventually gave getting better time fed records",
    "sentiment": "negative",
    "key_phrases": [
      "totally insane",
      "couple records",
      "getting better"
    ]
  },
  {
    "text": "m particularly interested complex classification examples reasoning llms new meaning interpretability easier interpret pull reasoning trace prompt reasoning ask example certain classification running chat harder neural networks hard layers prone making plausible sounding explanations bearing reality interestingly classifying encoder model like bert explaining resulting classification reasoning model gives solid results plausible explanations trying ml methods step gets slightly better results larger likelihood hallucinations reasoning",
    "sentiment": "positive",
    "key_phrases": [
      "complex classification",
      "interpretability easier",
      "plausible explanations"
    ]
  },
  {
    "text": "curiosity scientists measure performance genai know traditional ml model training sets test sets score test sets indicator performance model transferred genai objective generates exhibit data",
    "sentiment": "neutral",
    "key_phrases": [
      "model training",
      "test sets",
      "genai objective"
    ]
  },
  {
    "text": "adding need ability think design system like generate extremely high quality training data scale llm traininfer traditional models complexity went sourcingfinding getting right data tagged converted effectively write good prompts identify models use think loud find right problems solve design simple processes systems capability deliver goes massively focus system level thinking communication stakeholder management actual complexity traditional model building experimentation seat",
    "sentiment": "positive",
    "key_phrases": [
      "system level",
      "high quality",
      "stakeholder management"
    ]
  },
  {
    "text": "kind happening scenes llm good making correct decisions quickly working agentic application mcp architecture llm tools disposal reasons use tools imagining future tools understands use feature engineering data processing model architecture design model training processes",
    "sentiment": "positive",
    "key_phrases": [
      "correct decisions",
      "agentic application",
      "feature engineering"
    ]
  },
  {
    "text": "m asking possible soon saying trying create model real world data deploy production satisfy business requirement hell lot complex fitting model ve worked bunch production level models time spent stuff model fitting happens hour months iterative work",
    "sentiment": "negative",
    "key_phrases": [
      "complex fitting",
      "production level",
      "iterative work"
    ]
  },
  {
    "text": "believe op asking llm going better average arbitrary task painstakingly designed custom model task rewriting weights required",
    "sentiment": "negative",
    "key_phrases": [
      "painstakingly designed",
      "arbitrary task",
      "custom model"
    ]
  },
  {
    "text": "drawback course traceabilityauditability internal projects matter explain stakeholder m denying loan nt know little ai friend said default gon na fly lol",
    "sentiment": "negative",
    "key_phrases": [
      "drawback course",
      "stakeholder denying",
      "default gon"
    ]
  },
  {
    "text": "nt saw ve llms applied data like tabular data company works digital media like leads wet dream ask digital media immediately somewhat reliable answer having eggheads come mess tell hard usually",
    "sentiment": "negative",
    "key_phrases": [
      "digital media",
      "somewhat reliable",
      "hard usually"
    ]
  },
  {
    "text": "s suggested best practice imho issue classic ml modeling maybe automate prompt iterating writing prompt presumably wo nt fit prompt noise logic missed llm ignored focused etc earlier phases saying impossible engineer prompt eval set different beast high dimensional optimization limited training data",
    "sentiment": "negative",
    "key_phrases": [
      "classic ml",
      "high dimensional",
      "limited training"
    ]
  },
  {
    "text": "respect folks like neel nanda mi research nt commercial application nigh impossible practical sense understand reasoning transformer wrt complex classification experienced monthslong collaboration ai rangers microsoft finetune classifier enterprise data massively underwhelming systems nt exhaustively pretrained niche data case enterprise biotechnology data performance fewshot learning tasks meh powerful architectures course modern nlp nt api calls engineering hacks extend llm context improve inference performance country mile",
    "sentiment": "negative",
    "key_phrases": [
      "practical sense",
      "massively underwhelming",
      "fewshot learning"
    ]
  },
  {
    "text": "honestly way ask llm d hard know classic ml model decision know s lot work area asking llm easier interpretable edit lot downvotes help clarify position think lot classic explainable ml technics super reliable super understandable llms infallible hating explainable ml ve drive design ill d need solid empirical evidence convince classic explainable ml performs llms reliable explainability",
    "sentiment": "positive",
    "key_phrases": [
      "classic ml model",
      "explainable ml",
      "llms infallible"
    ]
  },
  {
    "text": "makes sense nlp tasks known gpt models outperform specialized models box cases efficient solution use huge model works",
    "sentiment": "positive",
    "key_phrases": [
      "nlp tasks",
      "efficient solution",
      "huge model"
    ]
  },
  {
    "text": "dunno got published internally model distillation getting labelled data scale expensive faith llm classifier use generate labeled data train model s cheaper inference",
    "sentiment": "negative",
    "key_phrases": [
      "model distillation",
      "expensive scale",
      "generate labeled"
    ]
  },
  {
    "text": "think depends lot classification task lm choice architecture built lm classification tasks tend contain lots text endless common sense edge cases need handling small lms decent reasoning realworld context help identify false positives going bit hybrid classifier encoder model pull features interest ramming encodings traditional ml classifier powerful encodings nt task specific helps ve got rich cot dataset work humanled classification process involves taking lot notes box fewshot learning suitable example selection careful multistep prompting gives fairly good reasoning classification including spotting pesky edge cases explaining humanreadable text far mi goes yeah academic pursuit right interesting results coming applied ml",
    "sentiment": "neutral",
    "key_phrases": [
      "classification task",
      "realworld context",
      "hybrid classifier"
    ]
  },
  {
    "text": "eventually fully expect llm trace decisionprediction tell decision making process mcp architecture",
    "sentiment": "neutral",
    "key_phrases": [
      "llm trace",
      "decision making",
      "mcp architecture"
    ]
  },
  {
    "text": "hear issue ml engineer accept llms reasoning non technical business person accepts llm decision",
    "sentiment": "negative",
    "key_phrases": [
      "ml engineer",
      "non technical",
      "llm decision"
    ]
  },
  {
    "text": "tell decision making process mcp architecture chainofthought cot offers potential boon ai safety allows monitoring models cot try understand intentions reasoning processes effectiveness monitoring hinges cots faithfully representing models actual reasoning processes",
    "sentiment": "positive",
    "key_phrases": [
      "ai safety",
      "monitoring models",
      "chain of thought"
    ]
  },
  {
    "text": "agree understandable non technical importnant understandable non technical person credit denied extensive history late payments unreliable current sources income ml engineer sad thing llms cut ml engineer pm wants needs data",
    "sentiment": "negative",
    "key_phrases": [
      "credit denied",
      "late payments",
      "ml engineer sad"
    ]
  },
  {
    "text": "described rudimentary approach model distillation basically larger model generate synthetic data data train smaller model mid level ml engineer wonder expertise true distillation better uses logits larger model train smaller model richer tapestry data synthetic logitless data",
    "sentiment": "neutral",
    "key_phrases": [
      "model distillation",
      "synthetic data",
      "mid level ml"
    ]
  },
  {
    "text": "github bytedanceseed basically approach model distillation pretrain finetune sft rl state art coding models base instructiontuned reasoning long paper explain detail learned",
    "sentiment": "neutral",
    "key_phrases": [
      "model distillation",
      "state art",
      "finetune models"
    ]
  },
  {
    "text": "comes answer probabilities nt know token predicted usually chain thought coherent",
    "sentiment": "negative",
    "key_phrases": [
      "answer probabilities",
      "nt know token",
      "chain thought"
    ]
  },
  {
    "text": "applying requirement explainable ml nt faith llms explaining reasoning reliable think probably reliably reasonable explanation output classic explainable ml method understandable nontechnical folks better measurable criteria ill note years working large tech company ve convinced vast majority ml engineers pms poor understanding howwhy models decisions said work discovery different fields like trust safety classifiers",
    "sentiment": "negative",
    "key_phrases": [
      "poor understanding",
      "explainable ml",
      "trust safety"
    ]
  },
  {
    "text": "m saying pms role completely saying pms involved building decision engine prompt engineering number technical staff required dropping incredibly task",
    "sentiment": "negative",
    "key_phrases": [
      "pms involved",
      "incredibly task",
      "technical staff"
    ]
  },
  {
    "text": "basically bringing model distillation nother level distilling filtering best outputs model want train",
    "sentiment": "positive",
    "key_phrases": [
      "model distillation",
      "best outputs",
      "train model"
    ]
  },
  {
    "text": "r introducing dreamprm multimodal llm reasoning method achieving place mathvista leaderboard excited share recent work dreamprm multimodal llm reasoning method ranks currently mathvista leaderboard reasoning substantially improved performance large language models llms complicated tasks central current reasoning studies process reward models prms offer finegrained evaluation intermediate reasoning steps guide reasoning process extending prms multimodal large language models mllms introduces challenges multimodal reasoning covers wider range tasks compared textonly scenarios resulting distribution shift training testing sets severe leading greater generalization difficulty training reliable multimodal prm demands large diverse datasets ensure sufficient coverage current multimodal reasoning datasets suffer marked quality imbalance degrades",
    "sentiment": "positive",
    "key_phrases": [
      "multimodal llm",
      "reasoning method",
      "mathvista leaderboard"
    ]
  },
  {
    "text": "dlooking hinglish codemixed hindienglish speech emotion audio datasets recommendations hi m working deep learning project involving emotion recognition hinglish codemixed hindienglish speech ve found plenty datasets english like ravdess iemocap hindi mucs openslr m having trouble locating datasets contain hinglish speech especially emotion labels know hinglish speech datasets codeswitched hindienglish emotionlabeled hinglish audio opensource research datasets allow type training public datasets d appreciate tips create augment scratch increase accuracy thanks advance",
    "sentiment": "neutral",
    "key_phrases": [
      "hinglish speech",
      "emotion recognition",
      "public datasets"
    ]
  },
  {
    "text": "sets datasets augment data sets use training models assuming training model use case",
    "sentiment": "neutral",
    "key_phrases": [
      "data sets",
      "training models",
      "use case"
    ]
  },
  {
    "text": "create dataset collecting hinglish speech youtube videos podcasts social media emotion labels natural language processing machine learning algorithms",
    "sentiment": "neutral",
    "key_phrases": [
      "natural language",
      "machine learning",
      "emotion labels"
    ]
  },
  {
    "text": "d simple questions thread post questions instead creating new thread encourage create new posts questions post instead thread stay alive posting date title thanks answering questions previous thread",
    "sentiment": "neutral",
    "key_phrases": [
      "post questions",
      "create new",
      "stay alive"
    ]
  },
  {
    "text": "question find postdoc ai noncs phd finalyear phd candidate noncs field research application modern ai models transformer gan stable diffusion mamba short work apply new models proposed cvpr icml field ultimate career goal core ai research transition seeking postdoctoral position computer science department primary objective postdoc gain experience publish toptier ai conferences like cvpr icml neurips recognize profile competitive cs pi relevant candidate current plan publish cvpr workshop know workshop paper nt competitive best approach think right like ask advice similar transition noncs phd postdoc csai",
    "sentiment": "neutral",
    "key_phrases": [
      "postdoc ai",
      "core ai",
      "computer science"
    ]
  },
  {
    "text": "looking guidance collaboration building sinhala language gpt chatbot open advice partnerships hi m working interesting challenging project building gptstyle ai chatbot sinhala language initially started hobby thinking simple ve realized bigger expensive task expected goal create multifunctional sinhala chatbot understand generate natural sinhala conversations perform tasks like translation web search knowledge retrieval handle multiturn conversations emotions different intents eventually serve users sinhala daily tasks education business ve started hardest building labeled dataset sinhala sentences responses researched data labeling intent detection sentiment tagging m realizing actual model training llm finetuning embeddings retrieval augmentation need guidance m looking advice worked llm finetuning",
    "sentiment": "positive",
    "key_phrases": [
      "gpt chatbot",
      "sinhala language",
      "multifunctional chatbot"
    ]
  },
  {
    "text": "d looking aipowered smart crop library nt hey m currently image cropping python pretty basic detects edges color gradients actual objects example photo coffee cup want recognize cup main subject crop smartcrop finds areas edgescontrast misses actual focal point looking python library uses aiml objectaware cropping identify main subjects people objects etc modern edge detection recommendations libraries actually understand s image thanks",
    "sentiment": "negative",
    "key_phrases": [
      "smart crop",
      "edge detection",
      "object aware"
    ]
  },
  {
    "text": "better luck finding binary segmentationbackground removal model detect foreground drawing bounding box padding build crop lightweight like heavier configurable like depending resource requirements",
    "sentiment": "neutral",
    "key_phrases": [
      "binary segmentation",
      "foreground drawing",
      "lightweight model"
    ]
  },
  {
    "text": "d alternatives segmentation models pytorch smp currently goto image segmentation generally good library like easy use support timm encoders super useful nt like type attention options decoder nt feel modern flexibleextensible d love able add custom bottleneck modules easily bottleneck features auxilliary classification tasks fan aux handled modernflexible options decoder suggestions cheers",
    "sentiment": "positive",
    "key_phrases": [
      "image segmentation",
      "easy use",
      "modern flexible"
    ]
  },
  {
    "text": "d petition requiring reviewers state conditions improving scores ve thinking opaque inconsistent peer reviews especially ml conferences requirement reviewers explicitly state conditions raise scores example authors add experiments xyz theoretical claim proven abc setup area chairs acs judge conditions reasonably met rebuttal updated submission leaving entirely whims reviewers revisit paper properly honestly suspect reviewers nt know exactly change mind added bonus acs provide firstpass summary reviews state conditions consider sufficient recommending acceptance think improve transparency accountability review process",
    "sentiment": "negative",
    "key_phrases": [
      "peer reviews",
      "raise scores",
      "revisit paper"
    ]
  },
  {
    "text": "read reviewers guide guidance questions reviewer makes focus things affect score normally questions main things affect scores authors want hear tho cases improve grade read paper narrow research area minimal chance misunderstanding core contribution rejecting paper grounds things easily quickly place cases write questions affect evaluation leads authors trying convince times complaining ac way getting good score working improving paper later submitting conference surprised times review paper sequentially submitted iclr icml neurips aamas authors nt change suggested require new experiments significant rewriting paper keeps rejected",
    "sentiment": "negative",
    "key_phrases": [
      "reviewer makes",
      "affect scores",
      "complaining ac"
    ]
  },
  {
    "text": "massive conferences acceptance rates possible authors prescriptive route acceptance gon na lead complaining authors believe ve met reviewers criteria nt accepted end day need accept conferences meant hard idea worthy publication neuripsicmliclr",
    "sentiment": "negative",
    "key_phrases": [
      "acceptance rates",
      "complaining authors",
      "worthy publication"
    ]
  },
  {
    "text": "peer review process traditionally worked works normal fields ml community optimized degenerated overfitted state run funky lotteries entire field sends papers end people reward cvs researchers strategies compatible model produce lot papers phdmasters students try crossinstitution collaborations possible strategies result lottery tickets",
    "sentiment": "negative",
    "key_phrases": [
      "peer review",
      "degenerated state",
      "lottery tickets"
    ]
  },
  {
    "text": "highly likely improve grade point mainly larger change requires work undergo review cases reivewer access fully updated work time review changed papers days think work profit question format theoretical work e g proving intermediate step detail valid think reviews ml conferences inconsistent opaque compared journals fields chance heaving discussion resubmission review pretty unique ml book increase effort reviewing reviewers submitted paper paid work",
    "sentiment": "negative",
    "key_phrases": [
      "review cases",
      "inconsistent opaque",
      "increase effort"
    ]
  },
  {
    "text": "reveal identity including authors reviewers acs releasing decision allows author ask reviewer facetoface",
    "sentiment": "neutral",
    "key_phrases": [
      "reveal identity",
      "authors reviewers",
      "facetoface reviewers"
    ]
  },
  {
    "text": "definitely nt peer review traditionally worked idea scoring system forth reviewers submitters scores change having rebuttals discussion phases score updates etc relatively new innovation specific fields especially machine learning computer science areas fields submit decision acceptance celebrate prepare submit examples similar direction like conditional acceptance early review opportunities conferences outside machine learning relatively minor norm",
    "sentiment": "positive",
    "key_phrases": [
      "innovation specific",
      "machine learning",
      "conditional acceptance"
    ]
  },
  {
    "text": "r interpreting large language models personality critical event analysis excited share new work supernova event dataset interpreting large language models personality critical event analysis accepted actionable interpretability workshop icml introducing supernova event dataset present new benchmark built realworld wikipedia articles including biographies historical milestones global news scientific discoveries including articles google deep research dataset introduces novel task critical event analysis interpreting behavioral pattern personality llms looking inside model activations traces ask separate llm judge events critical use external perspective decode models values reasoning traits early insights tends prioritize emotional interpersonal events focus strategic milestones scientific discovery highlights causal breakthroughs gemini",
    "sentiment": "positive",
    "key_phrases": [
      "large language",
      "critical event",
      "new benchmark"
    ]
  },
  {
    "text": "d review clearly llm report ac review gave acl calls grpo generalized reward preference optimization chatgpt thinks grpo says work use grpo domain talk introduction says missing specific evaluations present appendix says justify claim known domain asking chatgpt says know feels like reviewer wanted bad review asked llm write poor review clearly check output literally knows grpo stands group relative policy optimization reply reviewer pretending know heshe chatgpt reviews want rid review possible",
    "sentiment": "negative",
    "key_phrases": [
      "poor review",
      "bad experience",
      "chatgpt fails"
    ]
  },
  {
    "text": "point nt report suspected llm use report unqualified review review nt understand grpo d actually flag review unqualified maybe mention llmgenerated justification",
    "sentiment": "negative",
    "key_phrases": [
      "unqualified review",
      "llm use",
      "flag review"
    ]
  },
  {
    "text": "think reported nt hopes high paper recently rejected reviewers giving devastating comments points completely hallucinated requested experiments paper editor care gave copypaste answer understand dissapointment accept paper reviewers concerns",
    "sentiment": "negative",
    "key_phrases": [
      "devastating comments",
      "paper rejected",
      "reviewers concerns"
    ]
  },
  {
    "text": "happen open review submissions spent hours writing multipage response half reply aimed strength section strengths hallucinated asked reviewer nicely clarify found strengths correct claims reviewer replied course sent message ac referring poor quality review ac ended tossing review",
    "sentiment": "negative",
    "key_phrases": [
      "poor quality",
      "review process",
      "hours writing"
    ]
  },
  {
    "text": "definitely report major conferences plagued llmgenerated terrible quality reviews speak issue gets bigger",
    "sentiment": "negative",
    "key_phrases": [
      "terrible quality",
      "major conferences",
      "llm generated"
    ]
  },
  {
    "text": "got rejected llm generated review similar reviewer wanted bad review likely emailed ac sent generic response taken account taken account paper accepted reviews positive smh",
    "sentiment": "negative",
    "key_phrases": [
      "bad review",
      "generic response",
      "paper accepted"
    ]
  },
  {
    "text": "trying follow point trying interesting way verify reviewer use llm implications review paper",
    "sentiment": "neutral",
    "key_phrases": [
      "follow point",
      "review paper",
      "llm implications"
    ]
  },
  {
    "text": "s necessarily evidence reviewer llm reviewer outside expertise area ideal happens op add observation saying suspect llm review definite proof definetely need write rebuttal ps way nt matter ac agree practice use score icml reviewer nt fill form completely wrote review rejecting paper contacted ac rebuttal reviewer voting accept weak reject shitty review served tiebreaker reject paper",
    "sentiment": "negative",
    "key_phrases": [
      "reviewer expertise",
      "definite proof",
      "shitty review"
    ]
  },
  {
    "text": "sad state affairs ml conferences acs overlook issues way overworked limited capacity soliciting emergency reviews cover clearly nonsensical reviews",
    "sentiment": "negative",
    "key_phrases": [
      "sad state",
      "overworked limited",
      "emergency reviews"
    ]
  },
  {
    "text": "feel miccai reviews comfortable llm reviews easily tackle rebuttal instead asshole read abstract nt find table thinking paper contain hand influx submission makes difficult decent reviews feasible review papers conference change needed vadly",
    "sentiment": "negative",
    "key_phrases": [
      "llm reviews",
      "rebuttal instead",
      "decent reviews"
    ]
  },
  {
    "text": "m guessing reviewer paper author forced review order submit threatened having paper desk rejected nt fix review honestly repeat offenders bannedsuspended submitting poor",
    "sentiment": "negative",
    "key_phrases": [
      "poor review",
      "repeat offenders",
      "paper rejected"
    ]
  },
  {
    "text": "wholeheartedly agree ethics violation punished rejecting papers fair coauthors paper conference acs ai conferences absolutely livid llm reviews specifically instruct spcs challenge reviewers discussions toss reviews end conference reporting pc member usually forms candidates best pc member tell grossly unprofessional behaviour",
    "sentiment": "negative",
    "key_phrases": [
      "ethics violation",
      "grossly unprofessional",
      "fair coauthors"
    ]
  },
  {
    "text": "agree s tricky imo authors warned allowed fix review llm reviews completely undermine peer review system need dealt extremely harshly review simply discarded bad reviewer wins personally d feel embarrassed aggrieved paper rejected coauthor submitting llm review phd supervisor senior coauthor young mentees kind thing kind tbh student reviews ought checked",
    "sentiment": "negative",
    "key_phrases": [
      "peer review",
      "bad reviewer",
      "extremely harshly"
    ]
  },
  {
    "text": "neurips right crappy review wo nt able access reviews paper fix",
    "sentiment": "negative",
    "key_phrases": [
      "crappy review",
      "neurips paper",
      "access reviews"
    ]
  },
  {
    "text": "p ve built spec llmtollm comms combining semantic patterns structured syntax firstly total disclaimer months ago knew little llms people went rabbit hole started chatting ai m chap lot pattern recognition way work write music orchestras reading sort tugged pattern strings think ve found s pretty effective long story short noticed llms training data steeped greek mythology decided use shared knowledge compression add syntax llms understand clear keyvalue assignments causality progression etc ve combined layers create dsl s tokenefficient richer logically sound nt library need install spec llm ve tested understand box ve documented syntax semantics philosophy benchmarks github m",
    "sentiment": "positive",
    "key_phrases": [
      "pattern recognition",
      "shared knowledge",
      "key value assignments"
    ]
  },
  {
    "text": "p detect person looking screen opencv hi guys m sort noob computer vision came project detect person looking screen live stream guide existing solutions ve seen use mediapipes facemesh depreciated use complex deep learning models like avoid deep learning cnn approach things complicated atp future way opencv mediapipe ps sorry wrong tag mods",
    "sentiment": "negative",
    "key_phrases": [
      "noob computer",
      "deep learning",
      "complex models"
    ]
  },
  {
    "text": "similar project needed check looking screen nt wanna touch deep learning lol mediapipe face mesh eye landmarks checked iris opencv centered probably looking screen way guess distracted super accurate works tweak thresholds bit depending setup need cnns good",
    "sentiment": "neutral",
    "key_phrases": [
      "deep learning",
      "face mesh",
      "iris opencv"
    ]
  },
  {
    "text": "check opencvs faceutils module functions facial detection tracking help achieve need deep learning models",
    "sentiment": "neutral",
    "key_phrases": [
      "face detection",
      "deep learning",
      "facial tracking"
    ]
  },
  {
    "text": "d respond reviewers model worse larger models got review asking compare submission paper recent models models months submission acl rules compare model contemporary ran comparisons model worse m model thing smaller data etc severely resource constrained compete terms scale think paper makes important contribution match models scale better results report results models better risk reviewers lower scores kinda want explain authors scale completely different factors unfair comparison care average score wanted try raise findings honestly nt know defend having resources labsunis",
    "sentiment": "negative",
    "key_phrases": [
      "worse models",
      "resource constrained",
      "unfair comparison"
    ]
  },
  {
    "text": "available models family x order magnitude parameter count experiments future work compare scaling laws determine approach remains competitive similar compute complexity",
    "sentiment": "neutral",
    "key_phrases": [
      "future work",
      "parameter count",
      "scaling laws"
    ]
  },
  {
    "text": "think stated answer clearly nt compare model models parameter size want address larger models probably compare models adjustment chinchilla scaling laws",
    "sentiment": "neutral",
    "key_phrases": [
      "compare models",
      "parameter size",
      "scaling laws"
    ]
  },
  {
    "text": "reframe paper focusing achieving good results small models limited data explain work relevant",
    "sentiment": "neutral",
    "key_phrases": [
      "small models",
      "limited data",
      "good results"
    ]
  },
  {
    "text": "curiosity kind datasets working compute use experiments stronger theoretical justification alleviate reviewers concerns",
    "sentiment": "positive",
    "key_phrases": [
      "curiosity driven",
      "stronger experiments",
      "theoretical justification"
    ]
  },
  {
    "text": "potential solutions computational capacities scale models train data makes models comparable plot performance model size dataset size showing model worse outperform scaled size argue comparable different resource training rendering comparison point scope paper",
    "sentiment": "neutral",
    "key_phrases": [
      "model size",
      "computational capacities",
      "scaled size"
    ]
  },
  {
    "text": "reframing secret successful research hard achieve big things usually strive useful findings come project telling story findings",
    "sentiment": "positive",
    "key_phrases": [
      "successful research",
      "big things",
      "useful findings"
    ]
  },
  {
    "text": "think know models mention introduction probably nt know scale models andor mention weaknesses mentioned models",
    "sentiment": "neutral",
    "key_phrases": [
      "scale models",
      "nt know",
      "weaknesses mentioned"
    ]
  },
  {
    "text": "visionlanguage modelling space datasets heavy single machines heavily phd students time nt think theoretical justification applied",
    "sentiment": "negative",
    "key_phrases": [
      "heavy machines",
      "phd students",
      "theoretical justification"
    ]
  },
  {
    "text": "brought paper think valid ask differences terms performance basic question model needed ones exist maybe find distilled smaller version",
    "sentiment": "neutral",
    "key_phrases": [
      "paper think",
      "basic question",
      "distilled version"
    ]
  },
  {
    "text": "visionlanguage knowing problem hard lets sort visionocr example d argue nt need gigantic gorillion parameter llm adecuately solve size llm adjusted problem hand llm size like chatgpt overkill comes alot unused feature space probably wasted calculations energy rephrase draw strength equally interesting imo smaller model holds bigger models remember wrong resource constrained people nt access highend hardware master thesis day valiantly trained weeks mere edit d argue nt need gigantic gorillion parameter llm adecuately solve come arogant nt mean solve problem entirety ofcourse atleast intuitively suffice proven researchers past year",
    "sentiment": "negative",
    "key_phrases": [
      "vision ocr example",
      "llm size problem",
      "resource constrained"
    ]
  },
  {
    "text": "r free access build company experimenting new hardware long story short s idling tb ram tb storage m allowed play want cool ai research publish decent conference m caught research frontier use help collaborators understand neural networks cnns transformer models etc reasonable depth understanding sota probably time long access gpu",
    "sentiment": "positive",
    "key_phrases": [
      "new hardware",
      "ai research",
      "neural networks"
    ]
  },
  {
    "text": "company finding use case company experimenting best direction expertreference company chosen topic resources showing high impact company",
    "sentiment": "neutral",
    "key_phrases": [
      "company finding",
      "best direction",
      "high impact"
    ]
  },
  {
    "text": "company niche data easily develop dataset ready use machine finetune opensource models data check reasonable results project create internally finetuned modelvision text audio etc helps increasing skillset",
    "sentiment": "positive",
    "key_phrases": [
      "finetune models",
      "opensource models",
      "increasing skillset"
    ]
  },
  {
    "text": "spin open llms mistral etc compare snapshotbased orchestration runtimes like inferx traditional serving cold starts model swapping gpu utilization d surprised infra innovation wide open",
    "sentiment": "positive",
    "key_phrases": [
      "inferx traditional",
      "gpu utilization",
      "infra innovation"
    ]
  },
  {
    "text": "m interested comes know day heard quantization llms interesting think d like work inkling impact field today",
    "sentiment": "positive",
    "key_phrases": [
      "interesting think",
      "impact field",
      "llms interesting"
    ]
  },
  {
    "text": "company uses image video generation generic use case definitely interesting nt think greatest minds field nt working d focus niche thing",
    "sentiment": "negative",
    "key_phrases": [
      "generic use",
      "greatest minds",
      "nt working"
    ]
  },
  {
    "text": "kinds quantization experiments model efficency stuff distilation pruning etc good result distilling quantifying llm run smaller hardware course gb vram d want train big model maybe d try train som novel vision transformer stuff",
    "sentiment": "positive",
    "key_phrases": [
      "quantization experiments",
      "distilling models",
      "vision transformer"
    ]
  },
  {
    "text": "quantization extremely competitive field moment want publish maybe bit niche domain knowledge ml good place start d know chemistry ml far comparatively little effort people strong fields",
    "sentiment": "neutral",
    "key_phrases": [
      "competitive field",
      "niche domain",
      "ml good place"
    ]
  },
  {
    "text": "think work deep learning model improving health care like cancer detection early ideas",
    "sentiment": "positive",
    "key_phrases": [
      "deep learning",
      "health care",
      "cancer detection"
    ]
  },
  {
    "text": "oh knowledge chemistry ends grade chemistry maintain mild interest particular direction d suggest protein folding like alpha fold actually found kaggle competitions sounded interesting rna folding polymer properties prediction m afraid simply nt technical ability",
    "sentiment": "negative",
    "key_phrases": [
      "not technical",
      "rna folding",
      "protein folding"
    ]
  },
  {
    "text": "ah yeah probably difficult example maybe comparatively rare domain knowledge finance physics geosciences engineering healthcare etc etc example chemistry friend density functional theory calculations neural networks",
    "sentiment": "neutral",
    "key_phrases": [
      "domain knowledge",
      "functional theory",
      "neural networks"
    ]
  },
  {
    "text": "p wrote ptx kernels hey ve meaning dive nvidia ptx learn best doingso decided handwrite ptx kernels inferenceonly version andrej karpathys project surprise actually work saw performance improvement inference compared equivalent cuda implementation s benchmarks showed check code way documented entire experience multipart blog series including linebyline explanations translated cuda ptx introduction residual kernel ii gelu kernel iii encoder kernel iv layernorm kernel v softmax kernel vi attention kernel vii matmul kernel performance results s time writing ptx bugs missed optimization opportunities d love feedback fixes s experienced lowlevel gpu programming posted x looking forward thoughts suggestions",
    "sentiment": "positive",
    "key_phrases": [
      "performance improvement",
      "nvidia ptx",
      "inference only"
    ]
  },
  {
    "text": "d looking web annotation tool chrome extension labeling live websites m building dataset knowledge extraction model need label structured data thousands live websites ideally m looking tool provides chrome extension label live html elements real websites open sites browser task queue saves annotation snapshot dom state page supports exporting annotations later review screenshots m considering building custom tool prefer avoid distract core research know existing tool supports m",
    "sentiment": "neutral",
    "key_phrases": [
      "web annotation",
      "chrome extension",
      "knowledge extraction"
    ]
  },
  {
    "text": "check think pdb pythons native debugger llm inside breakpoint hit ask questions like function returning null items array strings condition loop break agent navigate stack inspect variables look code figure answer let know y think",
    "sentiment": "neutral",
    "key_phrases": [
      "pdb debugger",
      "breakpoint hit",
      "inspect variables"
    ]
  },
  {
    "text": "like concept pretty useful tool assumes run training loop debug mode feels like contrived solution useful actually understanding loss plateauing going giving insightful feedback regular code debugging right",
    "sentiment": "positive",
    "key_phrases": [
      "useful tool",
      "insightful feedback",
      "debug mode"
    ]
  },
  {
    "text": "s sweet op maybe consider vibe coding tools like widespread know sql fell flat face learning java",
    "sentiment": "neutral",
    "key_phrases": [
      "vibe coding",
      "know sql",
      "java learning"
    ]
  },
  {
    "text": "s ram consumption currently alot debuggers pycharm destroy ram reading big data debugging",
    "sentiment": "negative",
    "key_phrases": [
      "ram consumption",
      "big data",
      "debuggers pycharm"
    ]
  },
  {
    "text": "got confused second s aws redshift service data warehouse foundation model anthropic nt fine tune cost money api key anthropic run program",
    "sentiment": "negative",
    "key_phrases": [
      "aws redshift",
      "cost money",
      "anthropic model"
    ]
  },
  {
    "text": "hey good idea wonder better expose debugger tool instead models use",
    "sentiment": "positive",
    "key_phrases": [
      "good idea",
      "debugger tool",
      "better expose"
    ]
  },
  {
    "text": "fact project llm agent instruction use example pdb connect mcp server shell command line agents copilot cursor windsurf claude code codex builtin project concept good",
    "sentiment": "positive",
    "key_phrases": [
      "project concept",
      "claude code",
      "copilot cursor"
    ]
  },
  {
    "text": "d position machine learning conferences establish refutations critiques track abstract science progresses iteratively advancing correcting humanitys understanding world machine learning ml research rapid advancements led explosion publications led misleading incorrect flawed fraudulent studies accepted highlighted ml conferences fallibility peer review mistakes understandable ml conferences offer robust processes help field systematically correct errors position paper argues ml conferences establish dedicated refutations critiques r c track r c track provide highprofile reputable platform support vital research critically challenges prior research fostering dynamic selfcorrecting research ecosystem discuss key considerations including track design review principles potential pitfalls provide illustrative example submission concerning recent iclr",
    "sentiment": "negative",
    "key_phrases": [
      "ml conferences",
      "peer review",
      "flawed studies"
    ]
  },
  {
    "text": "absolutely love concept challenging ideas previous papers especially popularrespected work incredibly important branch science obviously need significant factual results bad good previously thought papers categories usually interesting papers inventing new",
    "sentiment": "positive",
    "key_phrases": [
      "challenging ideas",
      "popular respected",
      "incredibly important"
    ]
  },
  {
    "text": "absolutely challenges reproduction incentive opportunity cost time reproduce nt publish new paper llm decoding deterministic finite precision mitigated standard error standard error common ml community cost particularly pretraining postraining",
    "sentiment": "negative",
    "key_phrases": [
      "opportunity cost",
      "standard error",
      "mitigated time"
    ]
  },
  {
    "text": "heres example paper fit authors vision authorship overlaps seen similar openreview nt",
    "sentiment": "neutral",
    "key_phrases": [
      "example paper",
      "authorship overlaps",
      "openreview nt"
    ]
  }
]